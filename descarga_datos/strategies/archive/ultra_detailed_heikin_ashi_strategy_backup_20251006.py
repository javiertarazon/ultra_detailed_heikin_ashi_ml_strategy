#!/usr/bin/env python3
"""
ULTRA-DETAILED HEIKIN ASHI STRATEGY WITH REAL ML MODELS
=========================================================

Estrategia ultra-optimizada con                 n_jobs=1  # CAMBIADO de -1 a 1 para evitar problemas de memoriaodelos de machine learning REALES entrenados
con datos hist√≥ricos. NO USA SIMULACIONES - Aprende patrones y correlaciones
reales de indicadores t√©cnicos para generar operaciones de ALTA PROBABILIDAD.

CARACTER√çSTICAS:
- Modelos ML entrenados con datos hist√≥ricos reales (RandomForest, GradientBoosting, Neural Networks)
- Gesti√≥n de riesgo REAL basada en ATR y volatilidad del mercado
- Se√±ales de alta confianza (>70% ML confidence) + filtros t√©cnicos estrictos
- Trailing stops din√°micos y time exits
- Validaci√≥n completa de indicadores y datos

REQUIERE: Datos hist√≥ricos suficientes para entrenamiento ML (>100 muestras)
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple
import talib
from datetime import datetime, timedelta
import os
import pickle
import joblib
# Importaciones lazy de sklearn para compatibilidad Python 3.13
# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
# from sklearn.neural_network import MLPClassifier
# from sklearn.model_selection import train_test_split, cross_val_score
# from sklearn.preprocessing import StandardScaler
# from sklearn.metrics import accuracy_score, classification_report, roc_auc_score
import warnings
warnings.filterwarnings('ignore')

class MLModelManager:
    """
    Gestor de modelos de machine learning para predicci√≥n de se√±ales Heikin Ashi
    """

    def __init__(self, model_dir: str = "models"):
        self.model_dir = model_dir
        self.models = {}
        self.scalers = {}
        self.ensure_model_dir()

    def ensure_model_dir(self):
        """Crear directorio de modelos si no existe"""
        if not os.path.exists(self.model_dir):
            os.makedirs(self.model_dir)

    def get_model_path(self, symbol: str, model_name: str) -> str:
        """Obtener ruta del modelo"""
        # Para DOGE/USDT, buscar en models/DOGE/USDT_gradient_boosting.pkl
        if '/' in symbol:
            base, quote = symbol.split('/')
            return os.path.join(self.model_dir, base, f"{quote}_{model_name}.pkl")
        else:
            return os.path.join(self.model_dir, f"{symbol}_{model_name}.pkl")

    def get_scaler_path(self, symbol: str, model_name: str) -> str:
        """Obtener ruta del scaler"""
        # Para DOGE/USDT, buscar en models/DOGE/USDT_gradient_boosting_scaler.pkl
        if '/' in symbol:
            base, quote = symbol.split('/')
            return os.path.join(self.model_dir, base, f"{quote}_{model_name}_scaler.pkl")
        else:
            return os.path.join(self.model_dir, f"{symbol}_{model_name}_scaler.pkl")

    def prepare_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        Preparar features para el modelo ML
        """
        # Calcular Heikin Ashi primero
        data = self._calculate_heikin_ashi(data)

        # Calcular indicadores t√©cnicos
        data = self._calculate_technical_indicators(data)

        features = pd.DataFrame(index=data.index)

        # Features de Heikin Ashi
        features['ha_body_ratio'] = abs(data['ha_close'] - data['ha_open']) / (data['ha_high'] - data['ha_low'] + 1e-8)
        features['ha_trend_strength'] = (data['ha_close'] - data['ha_open']) / data['atr']
        features['ha_color_change'] = data['ha_color_change']

        # Features t√©cnicas principales
        features['stoch_k'] = data['stoch_k']
        features['stoch_d'] = data['stoch_d']
        features['cci'] = data['cci']
        features['rsi'] = data['rsi']
        features['macd'] = data['macd']
        features['macd_signal'] = data['macd_signal']
        features['macd_hist'] = data['macd_hist']

        # Features adicionales
        features['volume_ratio'] = data['volume_ratio']
        features['roc'] = data['roc']
        features['willr'] = data['willr']
        features['atr'] = data['atr']

        # Features de momentum
        features['price_change'] = data['close'].pct_change()
        features['volume_change'] = data['volume'].pct_change()

        # Features de volatilidad
        features['bb_upper'], features['bb_middle'], features['bb_lower'] = talib.BBANDS(data['close'], timeperiod=20)
        features['bb_width'] = (features['bb_upper'] - features['bb_lower']) / features['bb_middle']

        # Limpiar NaN y valores extremos
        features = features.fillna(0)
        features = features.replace([np.inf, -np.inf], 0)

        # Limitar valores extremos (winsorizing)
        for col in features.columns:
            if features[col].dtype in ['float64', 'float32']:
                # Limitar al percentil 1-99 para evitar outliers extremos
                lower = features[col].quantile(0.01)
                upper = features[col].quantile(0.99)
                features[col] = features[col].clip(lower, upper)

        return features

    def prepare_target(self, data: pd.DataFrame, lookahead: int = 1) -> pd.Series:
        """
        Preparar target: cambio de color Heikin Ashi en N periodos
        """
        # Target: 1 si hay cambio alcista, -1 si bajista, 0 si neutral
        future_changes = data['ha_color_change'].shift(-lookahead)
        target = pd.Series(0, index=data.index)

        # Solo considerar cambios significativos
        target[future_changes == 1] = 1   # Cambio alcista futuro
        target[future_changes == -1] = -1  # Cambio bajista futuro

        return target

    def train_models(
        self,
        data: pd.DataFrame,
        symbol: str,
        test_size: float = 0.2,
        cv_folds: int = 10,
        cv_jobs: int = 1,  # CAMBIADO de -1 a 1 para evitar problemas de memoria
        enable_cv: bool = True
    ):
        """
        Entrenar modelos de ML para un s√≠mbolo espec√≠fico
        """
        print(f"Entrenando modelos ML para {symbol}...")

        # Importaciones lazy de sklearn para compatibilidad Python 3.13
        try:
            from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
            from sklearn.neural_network import MLPClassifier
            from sklearn.model_selection import train_test_split, cross_val_score
            from sklearn.preprocessing import StandardScaler
            from sklearn.metrics import accuracy_score, classification_report, roc_auc_score
            print("Importaciones sklearn exitosas")
        except KeyboardInterrupt:
            print("KeyboardInterrupt durante importaci√≥n sklearn - abortando entrenamiento")
            return {}
        except Exception as e:
            print(f"Error importando sklearn: {e}")
            return {}

        # Preparar features y target
        features = self.prepare_features(data)
        target = self.prepare_target(data)

        # Remover filas con target NaN (futuro)
        valid_idx = target.dropna().index
        features = features.loc[valid_idx]
        target = target.loc[valid_idx]

        # Split de datos
        X_train, X_test, y_train, y_test = train_test_split(
            features, target, test_size=test_size, random_state=42, shuffle=False
        )

        # Escalar features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # SOLO RANDOM FOREST - Otros modelos causan problemas en Python 3.13
        models_config = {
            'random_forest': RandomForestClassifier(
                n_estimators=200,        # Aumentado de 100 (m√°s √°rboles = mejor generalizaci√≥n)
                max_depth=15,            # Aumentado de 10 (m√°s profundidad con m√°s data)
                min_samples_split=10,    # Reducido de 20 (menos restrictivo)
                min_samples_leaf=5,      # Reducido de 10 (permite m√°s detalle)
                max_features='sqrt',     # Mejor para evitar overfitting
                random_state=42,
                n_jobs=1
            )
            # GradientBoosting y NeuralNetwork DESHABILITADOS
        }

        # Entrenar y evaluar modelos
        results = {}
        for model_name, model in models_config.items():
            print(f"  Entrenando {model_name}...")

            # Entrenar
            model.fit(X_train_scaled, y_train)

            # Predecir
            y_pred = model.predict(X_test_scaled)
            y_pred_proba = model.predict_proba(X_test_scaled)

            # M√©tricas
            accuracy = accuracy_score(y_test, y_pred)
            auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr') if len(np.unique(y_test)) > 1 else 0.5

            if enable_cv and len(X_train_scaled) >= cv_folds:
                # Cross-validation configurable (default 10-fold)
                cv_scores = cross_val_score(
                    model,
                    X_train_scaled,
                    y_train,
                    cv=cv_folds,
                    scoring='accuracy',
                    n_jobs=cv_jobs
                )
                cv_score = cv_scores.mean()
                cv_std = cv_scores.std()
            else:
                cv_score = accuracy
                cv_std = 0.0

            results[model_name] = {
                'model': model,
                'accuracy': accuracy,
                'auc': auc,
                'cv_score': cv_score,
                'cv_std': cv_std,
                'scaler': scaler
            }

            if enable_cv and len(X_train_scaled) >= cv_folds:
                print(f"    {model_name}: Accuracy={accuracy:.4f}, AUC={auc:.4f}, CV={cv_score:.4f}¬±{cv_std:.4f}")
            else:
                print(f"    {model_name}: Accuracy={accuracy:.4f}, AUC={auc:.4f} (CV omitido por configuraci√≥n)")

            # Guardar modelo
            self.save_model(symbol, model_name, model, scaler)

        self.models[symbol] = results
        return results

    def save_model(self, symbol: str, model_name: str, model, scaler):
        """Guardar modelo entrenado"""
        model_path = self.get_model_path(symbol, model_name)
        scaler_path = self.get_scaler_path(symbol, model_name)

        # Crear directorio si no existe
        os.makedirs(os.path.dirname(model_path), exist_ok=True)

        joblib.dump(model, model_path)
        joblib.dump(scaler, scaler_path)

        print(f"    Modelo guardado: {model_path}")

    def load_model(self, symbol: str, model_name: str):
        """Cargar modelo entrenado"""
        model_path = self.get_model_path(symbol, model_name)
        scaler_path = self.get_scaler_path(symbol, model_name)

        if os.path.exists(model_path) and os.path.exists(scaler_path):
            model = joblib.load(model_path)
            scaler = joblib.load(scaler_path)
            return model, scaler
        else:
            return None, None

    def predict_signal(self, data: pd.DataFrame, symbol: str, model_name: str = 'gradient_boosting') -> pd.Series:
        """
        Generar predicciones de se√±ales usando modelo entrenado REAL
        NO USA SIMULACIONES - Requiere modelo entrenado con datos hist√≥ricos
        """
        # Cargar modelo entrenado (OBLIGATORIO)
        model, scaler = self.load_model(symbol, model_name)

        if model is None or scaler is None:
            raise ValueError(f"MODELO {model_name} NO ENCONTRADO para {symbol}. "
                           f"Ejecutar entrenamiento primero con datos hist√≥ricos reales.")

        # Preparar features con datos reales
        features = self.prepare_features(data)
        features_scaled = scaler.transform(features)

        # Predecir probabilidades usando modelo entrenado
        proba = model.predict_proba(features_scaled)

        # Convertir a confianza (probabilidad de cambio alcista - probabilidad de cambio bajista)
        confidence = proba[:, 2] - proba[:, 0] if proba.shape[1] > 2 else proba[:, 1] - 0.5

        # Normalizar a [0, 1] - confianza real del modelo
        confidence = (confidence + 1) / 2
        confidence = np.clip(confidence, 0, 1)

        return pd.Series(confidence, index=data.index, name='ml_confidence')

    def _calculate_heikin_ashi(self, data: pd.DataFrame) -> pd.DataFrame:
        """Calcular velas Heikin Ashi"""

        # Heikin Ashi calculation
        ha_close = (data['open'] + data['high'] + data['low'] + data['close']) / 4

        ha_open = pd.Series(index=data.index, dtype=float)
        ha_open.iloc[0] = (data['open'].iloc[0] + data['close'].iloc[0]) / 2

        for i in range(1, len(data)):
            ha_open.iloc[i] = (ha_open.iloc[i-1] + ha_close.iloc[i-1]) / 2

        ha_high = pd.concat([ha_open, ha_close, data['high']], axis=1).max(axis=1)
        ha_low = pd.concat([ha_open, ha_close, data['low']], axis=1).min(axis=1)

        # Agregar al DataFrame
        data['ha_open'] = ha_open
        data['ha_high'] = ha_high
        data['ha_low'] = ha_low
        data['ha_close'] = ha_close

        # Color change (se√±al principal)
        data['ha_color_change'] = (data['ha_close'] > data['ha_open']).astype(int).diff().fillna(0)
        data['ha_bullish'] = (data['ha_close'] > data['ha_open']).astype(int)
        data['ha_bearish'] = (data['ha_close'] < data['ha_open']).astype(int)

        return data

    def _calculate_technical_indicators(self, data: pd.DataFrame) -> pd.DataFrame:
        """Calcular indicadores t√©cnicos necesarios para ML"""
        try:
            # ATR
            data['atr'] = talib.ATR(data['high'], data['low'], data['close'], timeperiod=14)

            # Stochastic Oscillator
            data['stoch_k'], data['stoch_d'] = talib.STOCH(data['high'], data['low'], data['close'],
                                                          fastk_period=14, slowk_period=3, slowd_period=3)

            # CCI (Commodity Channel Index)
            data['cci'] = talib.CCI(data['high'], data['low'], data['close'], timeperiod=14)

            # RSI
            data['rsi'] = talib.RSI(data['close'], timeperiod=14)

            # MACD
            data['macd'], data['macd_signal'], data['macd_hist'] = talib.MACD(data['close'],
                                                                             fastperiod=12, slowperiod=26, signalperiod=9)

            # Volume Ratio (comparaci√≥n con promedio m√≥vil)
            data['volume_ratio'] = data['volume'] / data['volume'].rolling(window=20).mean()

            # ROC (Rate of Change)
            data['roc'] = talib.ROC(data['close'], timeperiod=10)

            # Williams %R
            data['willr'] = talib.WILLR(data['high'], data['low'], data['close'], timeperiod=14)

            # Llenar NaN
            data = data.fillna(0)

            return data

        except Exception as e:
            print(f"Error calculando indicadores t√©cnicos: {e}")
            return data


class UltraDetailedHeikinAshiStrategy:
    """
    Estrategia ultra-detallada con modelos ML reales entrenados
    """

    def __init__(self, config=None):
        # Manejar tanto objetos Config como diccionarios
        if config is None:
            self.config = {}
        elif hasattr(config, 'backtesting'):
            # Es un objeto Config - extraer par√°metros relevantes
            self.config = {
                'symbol': getattr(config.backtesting, 'symbols', ['DOGE/USDT'])[0] if hasattr(config.backtesting, 'symbols') and config.backtesting.symbols else 'DOGE/USDT',
                'timeframe': getattr(config.backtesting, 'timeframe', '1H') if hasattr(config.backtesting, 'timeframe') else '1H',
                'ml_threshold': 0.3,  # ULTRA PERMISIVO - m√°s se√±ales
                'stoch_overbought': 80,
                'stoch_oversold': 20,
                'cci_threshold': 100,
                'volume_ratio_min': 0.3,  # ULTRA PERMISIVO - m√°s entradas
                'liquidity_score_min': 5,  # BAJADO DE 75 A 5 - CR√çTICO PARA GENERAR TRADES
                'max_drawdown': 0.05,
                'max_portfolio_heat': 0.04,
                'max_concurrent_trades': 2,
                'kelly_fraction': 0.5
            }
        else:
            # Es un diccionario
            self.config = config

        # Extraer par√°metros con valores por defecto
        self.symbol = self.config.get('symbol', 'DOGE/USDT')
        self.timeframe = self.config.get('timeframe', '1H')

        # Par√°metros ultra-optimizados basados en an√°lisis (OPTIMIZADO para rentabilidad)
        self.ml_threshold = self.config.get('ml_threshold', 0.3)  # MUY PERMISIVO - m√°s se√±ales
        self.stoch_overbought = self.config.get('stoch_overbought', 75)  # M√°s bajo
        self.stoch_oversold = self.config.get('stoch_oversold', 25)  # M√°s alto
        self.cci_threshold = self.config.get('cci_threshold', 80)  # M√°s bajo
        self.volume_ratio_min = self.config.get('volume_ratio_min', 0.3)  # MUY PERMISIVO - permite m√°s entradas
        self.liquidity_score_min = self.config.get('liquidity_score_min', 5)  # BAJADO - m√°s permisivo con nueva f√≥rmula

        # NUEVOS PAR√ÅMETROS OPTIMIZADOS (agregados despu√©s de optimizaci√≥n)
        # Valores optimizados basados en backtesting Optuna (BTC/USDT como referencia)
        if 'BTC' in self.symbol:
            # Par√°metros optimizados para BTC/USDT
            self.volume_threshold = self.config.get('volume_threshold', 1.3)
            self.atr_multiplier = self.config.get('atr_multiplier', 3.4)
            self.stop_loss_pct = self.config.get('stop_loss_pct', 0.09)
            self.take_profit_pct = self.config.get('take_profit_pct', 0.19)
            self.rsi_overbought = self.config.get('rsi_overbought', 70)
            self.rsi_oversold = self.config.get('rsi_oversold', 30)
            self.stoch_overbought = self.config.get('stoch_overbought', 85)
            self.stoch_oversold = self.config.get('stoch_oversold', 25)
        elif 'TSLA' in self.symbol:
            # Par√°metros optimizados para TSLA/US
            self.volume_threshold = self.config.get('volume_threshold', 1.7)
            self.atr_multiplier = self.config.get('atr_multiplier', 2.0)
            self.stop_loss_pct = self.config.get('stop_loss_pct', 0.09)
            self.take_profit_pct = self.config.get('take_profit_pct', 0.15)
            self.rsi_overbought = self.config.get('rsi_overbought', 65)
            self.rsi_oversold = self.config.get('rsi_oversold', 30)
            self.stoch_overbought = self.config.get('stoch_overbought', 75)
            self.stoch_oversold = self.config.get('stoch_oversold', 15)
        else:
            # Valores por defecto basados en BTC/USDT (mejor score)
            self.volume_threshold = self.config.get('volume_threshold', 1.3)
            self.atr_multiplier = self.config.get('atr_multiplier', 3.4)
            self.stop_loss_pct = self.config.get('stop_loss_pct', 0.09)
            self.take_profit_pct = self.config.get('take_profit_pct', 0.19)
            self.rsi_overbought = self.config.get('rsi_overbought', 70)
            self.rsi_oversold = self.config.get('rsi_oversold', 30)

        # Gesti√≥n de riesgo avanzada OPTIMIZADA
        self.max_drawdown = self.config.get('max_drawdown', 0.05)
        self.max_portfolio_heat = self.config.get('max_portfolio_heat', 0.06)  # Aumentado a 6%
        self.max_concurrent_trades = self.config.get('max_concurrent_trades', 3)  # M√°s oportunidades
        self.kelly_fraction = self.config.get('kelly_fraction', 0.3)  # M√°s conservador

        # Estado interno
        self.active_trades = []
        self.portfolio_value = 10000.0  # Valor inicial
        self.current_drawdown = 0.0

        # Inicializar gestor de modelos ML
        self.ml_manager = MLModelManager()

    def run(self, data: pd.DataFrame, symbol: str, timeframe: str = '4h') -> Dict:
        """
        Ejecutar estrategia ultra-detallada con modelos ML reales entrenados
        REQUIERE datos hist√≥ricos reales para entrenamiento - NO SIMULACIONES

        Args:
            data: DataFrame con datos OHLCV hist√≥ricos reales
            symbol: S√≠mbolo del activo
            timeframe: Timeframe de los datos

        Returns:
            Dict con resultados de backtesting usando ML real
        """
        try:
            print(f"[START] Iniciando UltraDetailedHeikinAshiStrategy REAL ML para {symbol}")
            print(f"[DEBUG] M√©todo run() llamado con {len(data)} filas")

            # MODO SEGURO: Verificar si est√° activado para evitar problemas Python 3.13
            safe_mode = self.config.get('ml_training', {}).get('safe_mode', False)
            if safe_mode:
                print("üõ°Ô∏è  MODO SEGURO ACTIVADO - Usando solo indicadores t√©cnicos (sin ML)")
                return self._run_safe_mode(data, symbol, timeframe)

            # VALIDAR datos m√≠nimos para entrenamiento
            if len(data) < 100:
                raise ValueError(f"Datos insuficientes: {len(data)} filas. Necesario m√≠nimo 100 para ML real.")

            # Preparar datos con indicadores calculados correctamente
            data_processed = self._prepare_data(data.copy())
            print(f"Datos preparados: {len(data_processed)} filas con indicadores t√©cnicos completos")

            # FORZAR uso de modelos existentes (NO re-entrenar en cada ejecuci√≥n)
            model_exists = self.ml_manager.load_model(symbol, 'random_forest')[0] is not None  # CAMBIADO A RANDOM_FOREST
            should_retrain = not model_exists  # Solo entrenar si NO existe el modelo

            if should_retrain:
                print(f"‚ö†Ô∏è  Modelos ML no encontrados. Entrenando con {len(data_processed)} muestras...")
                self.ml_manager.train_models(data_processed, symbol)
                print("‚úÖ Modelos ML entrenados y guardados")
            else:
                print(f"‚úÖ Usando modelos ML existentes para {symbol} (skip re-training)")

            # CACHEAR predicciones ML usando modelo entrenado REAL
            print(f"Generando predicciones ML reales para {len(data_processed)} velas...")
            ml_confidence_cached = self.ml_manager.predict_signal(data_processed, symbol, 'random_forest')  # CAMBIADO A RANDOM_FOREST
            print(f"Predicciones ML reales: confianza {ml_confidence_cached.min():.3f} - {ml_confidence_cached.max():.3f}")

            # Generar se√±ales usando ML real + filtros t√©cnicos
            signals = self._generate_signals(data_processed, symbol, ml_confidence_cached)
            signals_above_threshold = (ml_confidence_cached > self.ml_threshold)
            print(f"Se√±ales ML reales: {signals.sum()} entradas largas, {(signals == -1).sum()} entradas cortas")
            print(f"Se√±ales con alta confianza (>{self.ml_threshold}): {signals_above_threshold.sum()}/{len(signals_above_threshold)}")

            # Ejecutar backtesting con gesti√≥n de riesgo real
            results = self._run_backtest(data_processed, signals, symbol, ml_confidence_cached)
            print(f"[RESULT] Backtesting completado: {results['total_trades']} trades, P&L: ${results['total_pnl']:.2f}")
            print(f"[DEBUG] run(): Trades en results = {len(results.get('trades', []))}")

            return results

        except Exception as e:
            print(f"[ERROR] Error en UltraDetailedHeikinAshiStrategy REAL ML: {e}")
            import traceback
            traceback.print_exc()
            return self._get_empty_results(symbol)

    def _prepare_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """Preparar datos con TODOS los indicadores t√©cnicos calculados correctamente"""

        # VALIDAR columnas requeridas
        required_cols = ['open', 'high', 'low', 'close', 'volume']
        missing_cols = [col for col in required_cols if col not in data.columns]
        if missing_cols:
            raise ValueError(f"Columnas requeridas faltantes: {missing_cols}")

            print(f"[CALC] Calculando indicadores t√©cnicos para {len(data)} velas...")        # 1. Heikin Ashi - CORRECTAMENTE calculado
        data = self._calculate_heikin_ashi(data)

        # 2. Indicadores t√©cnicos principales - VERIFICADOS con TA-Lib
        try:
            # Stochastic Oscillator
            data['stoch_k'], data['stoch_d'] = talib.STOCH(
                data['high'], data['low'], data['close'],
                fastk_period=14, slowk_period=3, slowd_period=3
            )

            # CCI (Commodity Channel Index)
            data['cci'] = talib.CCI(data['high'], data['low'], data['close'], timeperiod=14)

            # RSI
            data['rsi'] = talib.RSI(data['close'], timeperiod=14)

            # MACD
            data['macd'], data['macd_signal'], data['macd_hist'] = talib.MACD(
                data['close'], fastperiod=12, slowperiod=26, signalperiod=9
            )

            # ATR para gesti√≥n de riesgo REAL
            data['atr'] = talib.ATR(data['high'], data['low'], data['close'], timeperiod=14)

            # Volumen ratio - indicador de liquidez real
            data['volume_sma'] = talib.SMA(data['volume'], timeperiod=20)
            data['volume_ratio'] = data['volume'] / data['volume_sma']

            # Momentum adicional
            data['roc'] = talib.ROC(data['close'], timeperiod=10)
            data['willr'] = talib.WILLR(data['high'], data['low'], data['close'], timeperiod=14)

            # Bollinger Bands para volatilidad
            data['bb_upper'], data['bb_middle'], data['bb_lower'] = talib.BBANDS(
                data['close'], timeperiod=20, nbdevup=2, nbdevdn=2, matype=0
            )
            data['bb_width'] = (data['bb_upper'] - data['bb_lower']) / data['bb_middle']

            print("Todos los indicadores t√©cnicos calculados correctamente con TA-Lib")

        except Exception as e:
            raise ValueError(f"Error calculando indicadores t√©cnicos: {e}")

        # 3. VALIDAR que no hay NaN cr√≠ticos (m√°s tolerante)
        critical_indicators = ['ha_close', 'stoch_k', 'cci', 'rsi', 'macd', 'atr']
        nan_counts = data[critical_indicators].isna().sum()
        total_critical_nans = nan_counts.sum()
        max_allowed_nans = len(data) * 0.05  # M√°ximo 5% de NaN permitidos

        if total_critical_nans > max_allowed_nans:
            print(f"Ô∏è NaN detectados en indicadores cr√≠ticos: {nan_counts.to_dict()}")
            print(f"Limpiando {total_critical_nans} filas con NaN...")
            # En lugar de error, limpiar los NaN
            data = data.dropna(subset=critical_indicators)
            print(f"Datos limpiados: {len(data)} filas restantes")

        if len(data) < 50:
            raise ValueError(f"Datos insuficientes despu√©s de limpieza: {len(data)} filas")

        # 4. Rellenar NaN restantes en indicadores no cr√≠ticos
        data = data.fillna(method='bfill').fillna(method='ffill').fillna(0)

        print(f"Datos preparados: {len(data)} filas v√°lidas con todos los indicadores")
        return data

    def _calculate_heikin_ashi(self, data: pd.DataFrame) -> pd.DataFrame:
        """Calcular velas Heikin Ashi"""

        # Heikin Ashi calculation
        ha_close = (data['open'] + data['high'] + data['low'] + data['close']) / 4

        ha_open = pd.Series(index=data.index, dtype=float)
        ha_open.iloc[0] = (data['open'].iloc[0] + data['close'].iloc[0]) / 2

        for i in range(1, len(data)):
            ha_open.iloc[i] = (ha_open.iloc[i-1] + ha_close.iloc[i-1]) / 2

        ha_high = pd.concat([ha_open, ha_close, data['high']], axis=1).max(axis=1)
        ha_low = pd.concat([ha_open, ha_close, data['low']], axis=1).min(axis=1)

        # Agregar al DataFrame
        data['ha_open'] = ha_open
        data['ha_high'] = ha_high
        data['ha_low'] = ha_low
        data['ha_close'] = ha_close

        # Color change (se√±al principal)
        data['ha_color_change'] = (data['ha_close'] > data['ha_open']).astype(int).diff().fillna(0)
        data['ha_bullish'] = (data['ha_close'] > data['ha_open']).astype(int)
        data['ha_bearish'] = (data['ha_close'] < data['ha_open']).astype(int)

        return data

    def _generate_signals(self, data: pd.DataFrame, symbol: str, ml_confidence: pd.Series = None) -> pd.Series:
        """
        Generar se√±ales con ALTA PROBABILIDAD usando ML real + filtros t√©cnicos estrictos
        """
        signals = pd.Series(0, index=data.index, name='signal')

        # Usar ML confidence cacheado (OBLIGATORIO para se√±ales reales)
        if ml_confidence is None:
            raise ValueError("ML confidence requerido - debe usar modelo entrenado real")

        long_signals = 0
        short_signals = 0

        for i in range(1, len(data)):
            # CONFIRMAR ML confidence (umbral m√°s bajo para testing)
            ml_conf = ml_confidence.iloc[i]
            if ml_conf < 0.5:  # REDUCIDO A√öN M√ÅS para asegurar se√±ales
                continue

            # FILTROS T√âCNICOS M√ÅS RELAJADOS para testing
            ha_change_long = data['ha_color_change'].iloc[i] == 1
            ha_change_short = data['ha_color_change'].iloc[i] == -1

            # RSI: Rango amplio
            rsi = data['rsi'].iloc[i]
            rsi_ok = 20 < rsi < 80  # A√öN M√ÅS AMPLIO

            # Stochastic: Solo evitar extremos absolutos
            stoch_k = data['stoch_k'].iloc[i]
            stoch_ok = 10 < stoch_k < 90  # A√öN MENOS RESTRICTIVO

            # Volumen: M√≠nimo requerimiento
            volume_ok = data['volume_ratio'].iloc[i] > 0.8  # REDUCIDO A√öN M√ÅS

            # ATR: Rango amplio
            atr = data['atr'].iloc[i]
            atr_pct = atr / data['close'].iloc[i]
            volatility_ok = atr_pct > 0.001  # SOLO EVITAR VOLATILIDAD MUY BAJA

            # DEBUG: Contar condiciones cumplidas
            conditions_met = sum([ha_change_long or ha_change_short, rsi_ok, stoch_ok, volume_ok, volatility_ok])

            # SE√ëAL LONG: ML + HA + al menos 3 condiciones t√©cnicas
            if ha_change_long and conditions_met >= 3:
                signals.iloc[i] = 1  # Long
                long_signals += 1

            # SE√ëAL SHORT: ML + HA + al menos 3 condiciones t√©cnicas
            elif ha_change_short and conditions_met >= 3:
                signals.iloc[i] = -1  # Short
                short_signals += 1

        print(f"Se√±ales ML de ALTA PROBABILIDAD: {long_signals} LONG, {short_signals} SHORT")
        print(f"Confianza ML promedio en se√±ales: {ml_confidence[signals != 0].mean():.3f}")

        return signals

    def _check_liquidity_score(self, row: pd.Series) -> bool:
        """
        Verificar score de liquidez basado en volumen y volatilidad real
        AJUSTADO: F√≥rmulas m√°s permisivas y escalas razonables
        """
        # Volume score: 0-100, m√°s permisivo (x10 en lugar de x20)
        volume_score = min(row['volume_ratio'] * 10, 100)
        
        # Volatility score: 0-100, invertido (mayor ATR/close = mayor volatilidad = mayor score)
        # Usamos (atr/close)*100 directamente como medida de volatilidad
        volatility_pct = (row['atr'] / row['close']) * 100  # ej. 7.5% volatilidad
        volatility_score = min(volatility_pct * 10, 100)  # Escalar a 0-100
        
        liquidity_score = (volume_score + volatility_score) / 2
        
        # Prints de liquidity ELIMINADOS para no saturar logs
        
        return liquidity_score > self.liquidity_score_min

    def _run_backtest(self, data: pd.DataFrame, signals: pd.Series, symbol: str, ml_confidence_all: pd.Series) -> Dict:
        """Ejecutar backtesting con GESTI√ìN DE RIESGO REAL basada en ATR y volatilidad"""

        capital = self.portfolio_value
        trades = []
        peak_value = capital
        max_drawdown = 0
        position = 0
        entry_price = 0
        entry_time = None
        entry_index = None  # Para tracking de velas desde entrada

        # PAR√ÅMETROS DE RIESGO OPTIMIZADOS Y REALES
        risk_per_trade = 0.02  # 2% por trade (m√°s conservador)
        min_rr_ratio = 2.5     # Risk/Reward m√≠nimo m√°s alto
        max_concurrent_trades = self.max_concurrent_trades

        # CONTADORES para an√°lisis
        from utils.logger import get_logger

        logger = get_logger("ultra_detailed_strategy")
        signals_nonzero = signals[signals != 0]
        logger.info(f"DEBUG: {len(signals_nonzero)} se√±ales no-cero detectadas en serie signals")

        for i in range(len(data)):
            current_price = data['close'].iloc[i]
            current_time = data.index[i]
            atr = data['atr'].iloc[i]

            # SKIP si ATR es NaN o cero (primeras velas sin datos suficientes)
            if pd.isna(atr) or atr == 0:
                if i < 10:  # Solo log primeras 10
                    logger.debug(f"[DEBUG] Saltando i={i} - ATR NaN o cero: {atr}")
                continue

            # GESTI√ìN DE RIESGO REAL: Calcular position size basado en ATR
            if position == 0 and signals.iloc[i] != 0:
                # DEBUG: Primera se√±al v√°lida
                if len(trades) == 0:
                    logger.info(f"[SIGNAL] Primera se√±al v√°lida en i={i}: signal={signals.iloc[i]}, price={current_price}, atr={atr}")

                # CONFIRMAR se√±al con ML confidence alta
                ml_conf = ml_confidence_all.iloc[i]
                if ml_conf < self.ml_threshold:
                    if i < 30:  # Solo primeras 30 para no saturar
                        logger.debug(f"[DEBUG] Saltando i={i} - ML confidence baja: {ml_conf} < {self.ml_threshold}")
                    continue  # Skip se√±ales con baja confianza ML

                entry_price = current_price
                entry_time = current_time
                entry_index = i  # Guardar √≠ndice de entrada

                # STOP LOSS REAL basado en ATR (volatilidad real del mercado)
                atr_multiplier = 1.5  # 1.5 ATR para stop loss
                stop_distance = atr * atr_multiplier

                # TAKE PROFIT REAL: Risk/Reward ratio m√≠nimo
                take_profit_distance = stop_distance * min_rr_ratio

                # POSITION SIZE REAL: Basado en riesgo por trade + Kelly fraction
                risk_amount = capital * risk_per_trade
                position_size = risk_amount / stop_distance

                # AJUSTE KELLY: M√°s agresivo con alta confianza ML
                kelly_adjustment = self.kelly_fraction * ml_conf
                position_size *= kelly_adjustment

                # L√çMITES DE PORTFOLIO REALES
                active_trades_count = len([t for t in self.active_trades if t['status'] == 'open'])
                if active_trades_count >= max_concurrent_trades:
                    logger.debug(f"[DEBUG] Saltando i={i} - Max concurrent trades alcanzado: {active_trades_count} >= {max_concurrent_trades}")
                    continue

                # VALIDAR liquidez real antes de entrar
                current_row = data.iloc[i]
                if not self._check_liquidity_score(current_row):
                    logger.debug(f"[DEBUG] Saltando i={i} - Liquidity score bajo")
                    continue

                # ENTRAR POSICI√ìN
                position = signals.iloc[i] * position_size
                direction = 'long' if signals.iloc[i] > 0 else 'short'

                take_profit_price = entry_price + (signals.iloc[i] * take_profit_distance)
                stop_loss_price = entry_price - (signals.iloc[i] * stop_distance)

                trade = {
                    'entry_time': entry_time,
                    'entry_price': entry_price,
                    'position_size': position_size,
                    'direction': direction,
                    'stop_loss': stop_loss_price,
                    'take_profit': take_profit_price,
                    'status': 'open',
                    'symbol': symbol,
                    'ml_confidence': ml_conf,
                    'atr_at_entry': atr
                }

                self.active_trades.append(trade)
                print(f"[TRADE] Trade abierto en i={i}: {direction} {position_size:.4f} @ {entry_price:.2f}")

            # Gestionar posiciones abiertas con TRAILING STOP 50%
            elif position != 0:
                # TRAILING STOP DEL 50% - Stop loss se mueve al 50% del profit alcanzado
                unrealized_pnl = (current_price - entry_price) * position
                if unrealized_pnl > 0:  # En ganancia
                    # Calcular profit actual en t√©rminos de precio
                    profit_amount = abs(current_price - entry_price)  # Profit en precio
                    new_stop_distance = profit_amount * 0.5  # 50% del profit

                    if position > 0:  # Posici√≥n larga
                        new_stop = entry_price + new_stop_distance
                        # Solo mover stop loss si es mejor que el actual (m√°s alto)
                        if new_stop > stop_loss_price:
                            stop_loss_price = new_stop
                            print(f"Trailing stop 50% ajustado: {stop_loss_price:.6f} (profit: {profit_amount:.6f})")
                    else:  # Posici√≥n corta
                        new_stop = entry_price - new_stop_distance
                        # Solo mover stop loss si es mejor que el actual (m√°s bajo)
                        if new_stop < stop_loss_price:
                            stop_loss_price = new_stop
                            print(f"Trailing stop 50% ajustado: {stop_loss_price:.6f} (profit: {profit_amount:.6f})")

                    if position > 0:  # Posici√≥n larga
                        new_stop = entry_price + new_stop_distance
                        # Solo mover stop loss si es mejor que el actual (m√°s alto)
                        if new_stop > stop_loss_price:
                            stop_loss_price = new_stop
                            print(f"Trailing stop 50% ajustado: {stop_loss_price:.6f} (profit: {profit_amount:.6f})")
                    else:  # Posici√≥n corta
                        new_stop = entry_price - new_stop_distance
                        # Solo mover stop loss si es mejor que el actual (m√°s bajo)
                        if new_stop < stop_loss_price:
                            stop_loss_price = new_stop
                            print(f"Trailing stop 50% ajustado: {stop_loss_price:.6f} (profit: {profit_amount:.6f})")

                # Check condiciones de salida REALES
                exit_reason = None

                # 1. SE√ëAL CONTRARIA (reversi√≥n de Heikin Ashi)
                if signals.iloc[i] == -position:
                    exit_price = current_price
                    exit_reason = 'signal_reversal'

                # 2. TAKE PROFIT alcanzado
                elif (position > 0 and current_price >= take_profit_price) or (position < 0 and current_price <= take_profit_price):
                    exit_price = take_profit_price
                    exit_reason = 'take_profit'

                # 3. STOP LOSS alcanzado
                elif (position > 0 and current_price <= stop_loss_price) or (position < 0 and current_price >= stop_loss_price):
                    exit_price = stop_loss_price
                    exit_reason = 'stop_loss'

                # 4. TIME EXIT: M√°ximo 80 velas (4h * 80 = ~13 d√≠as) en posici√≥n (evitar stagnation)
                elif entry_index is not None and (i - entry_index) > 80:
                    exit_price = current_price
                    exit_reason = 'time_exit'

                else:
                    continue  # Mantener posici√≥n abierta

                # EJECUTAR SALIDA
                pnl = (exit_price - entry_price) * position                # DEBUG: Primer trade cerrado
                if len([t for t in self.active_trades if t['status'] == 'closed']) == 0:
                    print(f"Primer trade cerrado:")
                    print(f"   Entry: {entry_price:.6f} @ {entry_time}")
                    print(f"   Exit: {exit_price:.6f} @ {current_time}")
                    print(f"   Position: {position:.2f}")
                    print(f"   P&L: ${pnl:.2f} ({exit_reason})")

                # Actualizar trade
                for trade in self.active_trades:
                    if trade['status'] == 'open':
                        trade.update({
                            'exit_time': current_time,
                            'exit_price': exit_price,
                            'pnl': pnl,
                            'status': 'closed',
                            'exit_reason': exit_reason
                        })
                        # Agregar trade cerrado a la lista de resultados
                        trades.append(trade.copy())
                        break

                # Actualizar capital
                capital += pnl
                position = 0
                entry_price = 0

                # Actualizar drawdown
                peak_value = max(peak_value, capital)
                current_drawdown = (peak_value - capital) / peak_value
                max_drawdown = max(max_drawdown, current_drawdown)

                # Check max drawdown
                if current_drawdown > self.max_drawdown:
                    break  # Stop trading

        # Calcular m√©tricas finales
        total_trades = len([t for t in trades if t.get('exit_time')])
        winning_trades = len([t for t in trades if t.get('pnl', 0) > 0])
        losing_trades = total_trades - winning_trades
        
        # DEBUG: Verificar trades antes de retornar
        print(f"[DEBUG] _run_backtest: Total trades generados = {len(trades)}")
        print(f"[DEBUG] _run_backtest: Trades con exit_time = {total_trades}")
        if len(trades) > 0:
            print(f"[DEBUG] _run_backtest: Primer trade = {trades[0]}")
        else:
            print(f"[DEBUG] _run_backtest: NO SE GENERARON TRADES - Verificar condiciones")

        total_pnl = sum([t.get('pnl', 0) for t in trades])
        win_rate = winning_trades / total_trades if total_trades > 0 else 0

        # Calcular profit factor
        gross_profit = sum([t.get('pnl', 0) for t in trades if t.get('pnl', 0) > 0])
        gross_loss = abs(sum([t.get('pnl', 0) for t in trades if t.get('pnl', 0) < 0]))
        profit_factor = gross_profit / gross_loss if gross_loss > 0 else float('inf')

        return {
            'total_trades': total_trades,
            'winning_trades': winning_trades,
            'losing_trades': losing_trades,
            'win_rate': win_rate,
            'total_pnl': total_pnl,
            'gross_profit': gross_profit,
            'gross_loss': gross_loss,
            'profit_factor': profit_factor,
            'max_drawdown': max_drawdown,
            'final_capital': capital,
            'return_pct': (capital - self.portfolio_value) / self.portfolio_value,
            'symbol': symbol,
            'strategy_name': 'UltraDetailedHeikinAshiStrategy',
            'trades': trades
        }

    def _run_safe_mode(self, data: pd.DataFrame, symbol: str, timeframe: str) -> Dict:
        """
        Ejecutar estrategia en modo seguro (sin ML) para compatibilidad Python 3.13
        Usa solo indicadores t√©cnicos tradicionales
        """
        try:
            print(f"[SAFE MODE] Ejecutando estrategia sin ML para {symbol}")

            # Preparar datos con indicadores (sin ML)
            data_processed = self._prepare_data(data.copy())
            print(f"[SAFE MODE] Datos preparados: {len(data_processed)} filas")

            # Generar se√±ales usando SOLO indicadores t√©cnicos (sin ML)
            signals = self._generate_signals_safe_mode(data_processed, symbol)
            print(f"[SAFE MODE] Se√±ales generadas: {signals.sum()} largas, {(signals == -1).sum()} cortas")

            # Ejecutar backtesting con se√±ales t√©cnicas
            trades = self._execute_backtest(data_processed, signals, symbol)
            print(f"[SAFE MODE] Backtest completado: {len(trades)} trades")

            # Calcular m√©tricas finales
            return self._calculate_final_metrics(trades, symbol)

        except Exception as e:
            print(f"[SAFE MODE ERROR] Error en modo seguro: {e}")
            return self._get_empty_results(symbol)

    def _generate_signals_safe_mode(self, data: pd.DataFrame, symbol: str) -> pd.Series:
        """
        Generar se√±ales usando solo indicadores t√©cnicos (sin ML)
        L√≥gica simplificada para modo seguro
        """
        signals = pd.Series(0, index=data.index)

        try:
            # Condiciones t√©cnicas b√°sicas (sin ML)
            # Heikin Ashi trend
            ha_trend_up = (data['ha_close'] > data['ha_open']) & (data['ha_close'] > data['ha_close'].shift(1))
            ha_trend_down = (data['ha_close'] < data['ha_open']) & (data['ha_close'] < data['ha_close'].shift(1))

            # Volume confirmation
            volume_ok = data['volume'] > data['volume'].rolling(20).mean() * self.volume_threshold

            # RSI conditions
            rsi_oversold = data['rsi'] < self.stoch_oversold  # Usando stoch_oversold como threshold
            rsi_overbought = data['rsi'] > self.stoch_overbought

            # Trend strength (usando ATR ratio)
            trend_strength = abs(data['ema_10'] - data['ema_20']) / data['atr'] > 0.5

            # Se√±al de COMPRA: HA uptrend + volume + oversold + trend strength
            buy_signal = ha_trend_up & volume_ok & rsi_oversold & trend_strength

            # Se√±al de VENTA: HA downtrend + volume + overbought + trend strength
            sell_signal = ha_trend_down & volume_ok & rsi_overbought & trend_strength

            # Aplicar se√±ales
            signals[buy_signal] = 1
            signals[sell_signal] = -1

            print(f"[SAFE MODE] Condiciones aplicadas: HA trend, volume, RSI, trend strength")

        except Exception as e:
            print(f"[SAFE MODE] Error generando se√±ales: {e}")

        return signals

    def _get_empty_results(self, symbol: str) -> Dict:
        """Retornar resultados vac√≠os en caso de error"""
        return {
            'total_trades': 0,
            'winning_trades': 0,
            'losing_trades': 0,
            'win_rate': 0,
            'total_pnl': 0,
            'gross_profit': 0,
            'gross_loss': 0,
            'profit_factor': 0,
            'max_drawdown': 0,
            'final_capital': self.portfolio_value,
            'return_pct': 0,
            'symbol': symbol,
            'strategy_name': 'UltraDetailedHeikinAshiStrategy',
            'trades': []
        }