"""
M√≥dulo de almacenamiento de datos con manejo consistente de timestamps.
"""
import sqlite3
import os
import json
import pandas as pd
import numpy as np
from typing import Any, Dict, List, Optional, Union, Tuple
from core.base_data_handler import BaseDataHandler, DataValidationResult
from utils.logger import get_logger

logger = get_logger(__name__)

def _get_sqlite_type(dtype) -> str:
    """Maps pandas dtype to SQLite data type."""
    if pd.api.types.is_integer_dtype(dtype):
        return "INTEGER"
    if pd.api.types.is_float_dtype(dtype):
        return "REAL"
    # Timestamps and other objects will be stored as TEXT or INTEGER after conversion
    return "TEXT"

class DataStorage(BaseDataHandler):
    """Clase para el manejo de almacenamiento de datos."""
    
    def __init__(self, db_path: str = "data/data.db"):
        super().__init__()
        # Normalizar ruta: si comienza con "data/", cambiar a descarga_datos/data/
        if db_path.startswith("data/"):
            db_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), db_path)
        self.db_path = db_path
        self._ensure_db_path()
        # Compatibilidad: algunas llamadas antiguas referencian self.logger
        # Asignamos el logger de m√≥dulo para evitar AttributeError
        # Garantizar siempre un logger operativo (evita AttributeError en llamadas heredadas)
        try:
            if not hasattr(self, 'logger') or self.logger is None:
                self.logger = logger
        except Exception:
            # Fallback silencioso; en el peor caso se usar√° el logger de m√≥dulo directamente
            pass
    
    def _ensure_db_path(self):
        """Asegura que el directorio de la base de datos existe."""
        db_dir = os.path.dirname(self.db_path)
        if db_dir and not os.path.exists(db_dir):
            os.makedirs(db_dir, exist_ok=True)
            logger.info(f"Directorio creado: {db_dir}")
    
    def validate_data(self, data: Any) -> DataValidationResult:
        """
        Valida los datos proporcionados.

        Args:
            data: Datos a validar (DataFrame o lista de diccionarios)

        Returns:
            DataValidationResult con el resultado de la validaci√≥n
        """
        try:
            # Convertir a DataFrame si es necesario
            df = pd.DataFrame(data) if isinstance(data, list) else data

            # Usar la validaci√≥n espec√≠fica de timestamp
            return self.validate_timestamp_column(df)

        except Exception as e:
            return DataValidationResult(
                False,
                [f"Error en validaci√≥n de datos: {str(e)}"],
                []
            )
    
    def validate_timestamp_column(self, df: pd.DataFrame) -> DataValidationResult:
        """
        Valida la columna de timestamp en el DataFrame.
        
        Args:
            df: DataFrame a validar
            
        Returns:
            DataValidationResult con el resultado de la validaci√≥n
        """
        errors = []
        warnings = []
        
        # Verificar que existe columna timestamp
        if 'timestamp' not in df.columns:
            errors.append("Columna 'timestamp' no encontrada")
            return DataValidationResult(False, errors, warnings)
        
        # Verificar que no hay valores nulos
        null_count = df['timestamp'].isnull().sum()
        if null_count > 0:
            errors.append(f"Columna 'timestamp' tiene {null_count} valores nulos")
        
        # Verificar que los valores son v√°lidos
        try:
            ts_series = pd.to_datetime(df['timestamp'], errors='coerce')
            invalid_count = ts_series.isnull().sum()
            if invalid_count > 0:
                errors.append(f"Columna 'timestamp' tiene {invalid_count} valores inv√°lidos")
        except Exception as e:
            errors.append(f"Error convirtiendo timestamps: {e}")
        
        # Verificar orden temporal
        if len(df) > 1:
            is_sorted = df['timestamp'].is_monotonic_increasing
            if not is_sorted:
                warnings.append("Los timestamps no est√°n en orden ascendente")
        
        return DataValidationResult(len(errors) == 0, errors, warnings)
    
    def save_to_sqlite(self, data: Union[pd.DataFrame, List[Dict[str, Any]]], 
                      table_name: str,
                      validate: bool = True) -> bool:
        """
        Guarda datos en SQLite con manejo consistente de timestamps.
        
        Args:
            data: DataFrame o lista de diccionarios con los datos
            table_name: Nombre de la tabla
            validate: Si se debe validar los datos antes de guardar
            
        Returns:
            bool: True si se guard√≥ correctamente, False en caso contrario
        """
        try:
            # Convertir a DataFrame si es necesario
            df = pd.DataFrame(data) if isinstance(data, list) else data.copy()
            
            # Asegurar que el √≠ndice sea parte de las columnas si es timestamp
            if isinstance(df.index, pd.DatetimeIndex):
                df = df.reset_index()
            
            # Validar datos si se requiere
            if validate:
                validation_result = self.validate_timestamp_column(df)
                if not validation_result.is_valid:
                    for error in validation_result.errors:
                        logger.error(f"Error de validaci√≥n: {error}")
                    return False
                
                for warning in validation_result.warnings:
                    logger.warning(warning)
            
            # Preparar tipos de datos y convertir timestamps
            # Cuando se lee desde un CSV o DataFrame, asegurarse de que los timestamps est√©n en el formato correcto
            if 'timestamp' in df.columns:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                # Convertir a Unix timestamp en segundos
                df['timestamp'] = df['timestamp'].astype(np.int64) // 10**9
                # Validar rango temporal
                min_ts = int(pd.Timestamp('1970-01-01').timestamp())
                max_ts = int(pd.Timestamp('2050-01-01').timestamp())
                if (df['timestamp'] < min_ts).any() or (df['timestamp'] > max_ts).any():
                    raise ValueError(f"Timestamps fuera del rango v√°lido: 1970-01-01 a 2050-01-01")
            
            # Preparar tipos de datos para SQLite
            for col in df.columns:
                # Serializar objetos complejos
                if df[col].dtype == 'object':
                    if any(isinstance(x, (dict, list)) for x in df[col].dropna()):
                        df[col] = df[col].apply(lambda x: json.dumps(x) if isinstance(x, (dict, list)) else x)
            
            # Guardar en SQLite con transacci√≥n at√≥mica
            with sqlite3.connect(self.db_path) as conn:
                # Iniciar transacci√≥n
                conn.execute("BEGIN")
                
                try:
                    # Crear tabla si no existe
                    column_definitions = []
                    for col in df.columns:
                        if col == 'timestamp':
                            dtype = 'INTEGER'
                        elif pd.api.types.is_float_dtype(df[col]):
                            dtype = 'REAL'
                        elif pd.api.types.is_integer_dtype(df[col]):
                            dtype = 'INTEGER'
                        else:
                            dtype = 'TEXT'
                        column_definitions.append(f"{col} {dtype}")
                    
                    create_table_sql = f"""
                    CREATE TABLE IF NOT EXISTS {table_name} (
                        {', '.join(column_definitions)}
                    )
                    """
                    
                    # Crear tabla
                    conn.execute(create_table_sql)
                    
                    # Eliminar datos existentes si hay
                    try:
                        delete_sql = f"DELETE FROM {table_name}"
                        conn.execute(delete_sql)
                    except sqlite3.OperationalError:
                        pass  # La tabla no existe, lo cual est√° bien
                    
                    # Guardar los datos
                    df.to_sql(table_name, conn, if_exists='append', index=False)
                    
                    # Confirmar transacci√≥n
                    conn.commit()
                    return True
                    
                except Exception as e:
                    # Revertir transacci√≥n en caso de error
                    conn.rollback()
                    raise e
                
        except Exception as e:
            logger.error(f"Error guardando datos en SQLite: {e}")
            return False
    
    def save_data(self, table_name: str, data: pd.DataFrame) -> bool:
        """
        M√©todo principal para guardar datos. Limpia la tabla si existe.
        
        Args:
            table_name: Nombre de la tabla
            data: DataFrame con los datos a guardar
            
        Returns:
            bool: True si se guard√≥ correctamente
        """
        try:
            # Si la tabla existe, eliminar sus datos
            if self.table_exists(table_name):
                with sqlite3.connect(self.db_path) as conn:
                    conn.execute(f"DROP TABLE IF EXISTS {table_name}")
            
            # Guardar los nuevos datos
            return self.save_to_sqlite(data, table_name)
        except Exception as e:
            logger.error(f"Error en save_data: {e}")
            return False
    
    def table_exists(self, table_name: str) -> bool:
        """
        Verifica si una tabla existe en la base de datos.
        
        Args:
            table_name: Nombre de la tabla a verificar
            
        Returns:
            bool: True si la tabla existe
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT name FROM sqlite_master 
                    WHERE type='table' AND name=?
                """, (table_name,))
                return cursor.fetchone() is not None
        except Exception as e:
            logger.error(f"Error verificando tabla: {e}")
            return False
    
    def query_data(self, table_name: str, start_ts: Optional[int] = None, end_ts: Optional[int] = None) -> pd.DataFrame:
        """
        Consulta datos de la base de datos con filtros opcionales de timestamp.
        
        Args:
            table_name: Nombre de la tabla
            start_ts: Timestamp inicial en segundos (opcional)
            end_ts: Timestamp final en segundos (opcional)
            
        Returns:
            pd.DataFrame: DataFrame con los datos consultados
        """
        try:
            # Verificar si la tabla existe
            if not self.table_exists(table_name):
                # Usar tanto self.logger (si existe) como logger de m√≥dulo para robustez
                try:
                    self.logger.error(f"La tabla {table_name} no existe")
                except Exception:
                    logger.error(f"La tabla {table_name} no existe")
                return pd.DataFrame()

            # Construir la consulta SQL
            query = f"SELECT * FROM {table_name}"
            params = []
            
            if start_ts is not None and end_ts is not None:
                query += " WHERE timestamp >= ? AND timestamp <= ?"
                params.extend([start_ts, end_ts])
            
            query += " ORDER BY timestamp"
            
            # Ejecutar la consulta
            with sqlite3.connect(self.db_path) as conn:
                df = pd.read_sql_query(query, conn, params=params if params else None)
            
            if df.empty:
                try:
                    self.logger.warning(f"No se encontraron datos en la tabla {table_name}")
                except Exception:
                    logger.warning(f"No se encontraron datos en la tabla {table_name}")
                return pd.DataFrame()
            
            # Verificar que existe la columna timestamp
            if 'timestamp' not in df.columns:
                try:
                    self.logger.error(f"La columna timestamp no existe en la tabla {table_name}")
                except Exception:
                    logger.error(f"La columna timestamp no existe en la tabla {table_name}")
                return pd.DataFrame()
            
            # Convertir timestamp a datetime y establecer como √≠ndice
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')
            df = df.sort_values('timestamp')
                
            return df
            
        except Exception as e:
            try:
                self.logger.error(f"Error consultando datos: {e}")
            except Exception:
                logger.error(f"Error consultando datos: {e}")
            return pd.DataFrame()

    # ===================== METADATA SUPPORT =====================
    def _ensure_metadata_table(self):
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute(
                    """
                    CREATE TABLE IF NOT EXISTS data_metadata (
                        symbol TEXT NOT NULL,
                        timeframe TEXT NOT NULL,
                        start_ts INTEGER,
                        end_ts INTEGER,
                        records INTEGER,
                        coverage_pct REAL,
                        asset_class TEXT,
                        source_exchange TEXT,
                        last_update_ts INTEGER DEFAULT (strftime('%s','now')),
                        PRIMARY KEY(symbol,timeframe)
                    )
                    """
                )
        except Exception as e:
            try:
                self.logger.error(f"Error creando tabla metadata: {e}")
            except Exception:
                logger.error(f"Error creando tabla metadata: {e}")

    def upsert_metadata(self, row: dict):
        self._ensure_metadata_table()
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute(
                    """
                    INSERT INTO data_metadata(symbol,timeframe,start_ts,end_ts,records,coverage_pct,asset_class,source_exchange,last_update_ts)
                    VALUES(?,?,?,?,?,?,?, ?,strftime('%s','now'))
                    ON CONFLICT(symbol,timeframe) DO UPDATE SET
                        start_ts=excluded.start_ts,
                        end_ts=excluded.end_ts,
                        records=excluded.records,
                        coverage_pct=excluded.coverage_pct,
                        asset_class=excluded.asset_class,
                        source_exchange=excluded.source_exchange,
                        last_update_ts=strftime('%s','now')
                    """,
                    (
                        row.get('symbol'),
                        row.get('timeframe'),
                        row.get('start_ts'),
                        row.get('end_ts'),
                        row.get('records'),
                        row.get('coverage_pct'),
                        row.get('asset_class'),
                        row.get('source_exchange', 'unknown')
                    )
                )
        except Exception as e:
            try:
                self.logger.error(f"Error upsert metadata: {e}")
            except Exception:
                logger.error(f"Error upsert metadata: {e}")

    def get_metadata(self, symbol: str, timeframe: str) -> Optional[dict]:
        self._ensure_metadata_table()
        try:
            with sqlite3.connect(self.db_path) as conn:
                cur = conn.cursor()
                cur.execute(
                    "SELECT symbol,timeframe,start_ts,end_ts,records,coverage_pct,asset_class,source_exchange,last_update_ts FROM data_metadata WHERE symbol=? AND timeframe=?",
                    (symbol, timeframe)
                )
                row = cur.fetchone()
                if not row:
                    return None
                keys = ['symbol','timeframe','start_ts','end_ts','records','coverage_pct','asset_class','source_exchange','last_update_ts']
                return dict(zip(keys,row))
        except Exception as e:
            try:
                self.logger.error(f"Error get_metadata: {e}")
            except Exception:
                logger.error(f"Error get_metadata: {e}")
            return None

def save_to_csv(data: Union[pd.DataFrame, List[Dict[str, Any]]], 
              filepath: str,
              storage: Optional[DataStorage] = None) -> bool:
    """
    Guarda datos en CSV con manejo consistente de timestamps.
    
    Args:
        data: DataFrame o lista de diccionarios con los datos
        filepath: Ruta del archivo CSV
        storage: Instancia opcional de DataStorage para validaci√≥n
        
    Returns:
        bool: True si se guard√≥ correctamente, False en caso contrario
    """
    try:
        # Convertir a DataFrame si es necesario
        df = pd.DataFrame(data) if isinstance(data, list) else data.copy()
        
        # Validar si hay storage
        if storage:
            validation_result = storage.validate_timestamp_column(df)
            if not validation_result.is_valid:
                logger.error("Datos inv√°lidos para guardar en CSV")
                return False
        
        # Crear directorio si no existe
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        # Guardar en CSV
        df.to_csv(filepath, index=False)
        logger.info(f"Data saved to CSV: {filepath}")
        return True
        
    except Exception as e:
        logger.error(f"Error guardando datos en CSV: {str(e)}")
        return False



# Additional functions for specific data types can be added here

# M√©todos adicionales para compatibilidad con c√≥digo centralizado
def get_data_without_validation(self, symbol: str, timeframe: str, start_date: str = None, end_date: str = None):
    """
    M√©todo para obtener datos SIN validaci√≥n de autenticidad.
    Este m√©todo est√° dise√±ado para ser utilizado SOLO por validadores de datos.
    
    Args:
        symbol: S√≠mbolo a obtener
        timeframe: Timeframe a obtener
        start_date: Fecha inicial opcional en formato 'YYYY-MM-DD'
        end_date: Fecha final opcional en formato 'YYYY-MM-DD'
        
    Returns:
        pd.DataFrame o None si no hay datos
    """
    try:
        # Generar nombre de tabla est√°ndar
        table_name = f"{symbol.replace('/', '_')}_{timeframe}"
        
        # Convertir fechas a timestamps si se proporcionan
        start_ts = None
        end_ts = None
        
        if start_date:
            from datetime import datetime
            start_dt = datetime.strptime(start_date, '%Y-%m-%d')
            start_ts = int(start_dt.timestamp())
        
        if end_date:
            from datetime import datetime
            end_dt = datetime.strptime(end_date, '%Y-%m-%d')
            end_ts = int(end_dt.timestamp())
        
        # Usar query_data existente
        data = self.query_data(table_name, start_ts, end_ts)
        
        if data.empty:
            return None
        
        return data
        
    except Exception as e:
        logger.error(f"Error en get_data_without_validation: {e}")
        return None

def get_data_method(self, symbol: str, timeframe: str, start_date: str = None, end_date: str = None):
    """
    M√©todo de compatibilidad para obtener datos con la interfaz esperada por main.py.
    Incluye validaci√≥n opcional de autenticidad de datos.
    
    Args:
        symbol: S√≠mbolo a obtener
        timeframe: Timeframe a obtener
        start_date: Fecha inicial opcional en formato 'YYYY-MM-DD'
        end_date: Fecha final opcional en formato 'YYYY-MM-DD'
        
    Returns:
        pd.DataFrame o None si no hay datos
    """
    try:
        # Obtener datos sin validaci√≥n
        data = self.get_data_without_validation(symbol, timeframe, start_date, end_date)
        
        if data is None or data.empty:
            return None
            
        # Verificar si se requiere validaci√≥n de autenticidad
        try:
            import os
            validate_auth = os.environ.get('BT_VALIDATE_AUTH', '').lower() == 'true'
            
            if validate_auth and len(data) >= 100:
                # Importar validador solo si es necesario
                from utils.audit_real_data import validate_data_authenticity
                
                # Validar autenticidad
                validation = validate_data_authenticity(data, symbol, timeframe)
                
                # Registrar advertencia si los datos son sospechosos
                if not validation['is_authentic'] and validation['confidence'] < 50:
                    logger.warning(f"‚ö†Ô∏è ADVERTENCIA: Datos de {symbol} ({timeframe}) son sospechosos - {validation['reason']}")
                    # No bloqueamos el acceso, solo advertimos
        except ImportError:
            # Si no se puede importar el validador, continuamos sin validaci√≥n
            pass
        except Exception as e:
            logger.error(f"Error en validaci√≥n de datos para {symbol}: {e}")
        
        return data
        
    except Exception as e:
        logger.error(f"Error en get_data: {e}")
        return None

def save_data_method(self, data: pd.DataFrame, symbol: str, timeframe: str):
    """
    M√©todo de compatibilidad para guardar datos con la interfaz esperada por main.py
    """
    try:
        # Generar nombre de tabla est√°ndar
        table_name = f"{symbol.replace('/', '_')}_{timeframe}"
        
        # Usar save_data existente
        return self.save_data(table_name, data)
        
    except Exception as e:
        logger.error(f"Error en save_data: {e}")
        return False

# Asignar m√©todo de conveniencia para acceso directo
DataStorage.get_data_without_validation = get_data_without_validation

# Agregar m√©todos a la clase DataStorage
DataStorage.get_data = get_data_method
DataStorage.get_data_without_validation = get_data_without_validation
DataStorage.save_data_compat = save_data_method

# Sobreescribir save_data para manejar ambas interfaces
original_save_data = DataStorage.save_data
def save_data_unified(self, table_name_or_data, data_or_symbol=None, timeframe=None):
    """M√©todo unificado que maneja ambas interfaces de save_data"""
    if isinstance(table_name_or_data, pd.DataFrame) and data_or_symbol and timeframe:
        # Nueva interfaz: save_data(dataframe, symbol, timeframe)
        return save_data_method(self, table_name_or_data, data_or_symbol, timeframe)
    else:
        # Interfaz original: save_data(table_name, dataframe)
        return original_save_data(self, table_name_or_data, data_or_symbol)

DataStorage.save_data = save_data_unified

# Alias para compatibilidad con c√≥digo centralizado
StorageManager = DataStorage

async def ensure_data_availability(symbol: str, timeframe: str = '4h', 
                                 start_date: str = None, end_date: str = None,
                                 config: dict = None) -> pd.DataFrame:
    """
    Funci√≥n centralizada para asegurar disponibilidad de datos hist√≥ricos.
    
    FLUJO CENTRALIZADO:
    1. Verificar SQLite (prioridad #1)
    2. Si no existe en SQLite, verificar CSV (fallback)
    3. Si no existe en ninguno, descargar autom√°ticamente
    4. Retornar datos disponibles
    
    Args:
        symbol: S√≠mbolo a verificar (ej: 'BTC/USDT', 'TSLA/US')
        timeframe: Timeframe deseado (ej: '4h', '1d')
        start_date: Fecha inicio (YYYY-MM-DD)
        end_date: Fecha fin (YYYY-MM-DD)
        config: Configuraci√≥n del sistema
        
    Returns:
        DataFrame con datos hist√≥ricos
    """
    logger.info(f"üîç Verificando disponibilidad de datos para {symbol} en {timeframe}")
    
    # Cargar configuraci√≥n si no se proporciona
    if config is None:
        try:
            from config.config_loader import load_config_from_yaml
            config = load_config_from_yaml()
        except Exception as e:
            logger.error(f"Error cargando configuraci√≥n: {e}")
            raise
    
    # Determinar fechas si no se especifican
    if start_date is None or end_date is None:
        # Usar fechas por defecto del config o valores razonables
        try:
            if hasattr(config, 'backtesting'):
                if start_date is None:
                    start_date = getattr(config.backtesting, 'start_date', '2023-01-01')
                if end_date is None:
                    end_date = getattr(config.backtesting, 'end_date', pd.Timestamp.now().strftime('%Y-%m-%d'))
            else:
                if start_date is None:
                    start_date = '2023-01-01'
                if end_date is None:
                    end_date = pd.Timestamp.now().strftime('%Y-%m-%d')
        except Exception as e:
            logger.warning(f"Error obteniendo fechas de config, usando valores por defecto: {e}")
            if start_date is None:
                start_date = '2023-01-01'
            if end_date is None:
                end_date = pd.Timestamp.now().strftime('%Y-%m-%d')
    
    # 1. PRIMERO: Verificar SQLite (prioridad m√°xima)
    storage = DataStorage()
    table_name = f"{symbol.replace('/', '_')}_{timeframe}"
    
    try:
        sqlite_data = storage.get_data_without_validation(symbol, timeframe, start_date, end_date)
        if sqlite_data is not None and not sqlite_data.empty:
            # Verificar que los datos cubren el per√≠odo solicitado
            if _data_covers_period(sqlite_data, start_date, end_date):
                logger.info(f"‚úÖ Datos encontrados en SQLite para {symbol}: {len(sqlite_data)} filas")
                return sqlite_data
            else:
                logger.warning(f"‚ö†Ô∏è Datos en SQLite incompletos para {symbol}, descargando datos adicionales")
    except Exception as e:
        logger.warning(f"Error verificando SQLite para {symbol}: {e}")
    
    # 2. SEGUNDO: Verificar CSV (fallback)
    try:
        csv_data = _load_csv_data(symbol, timeframe)
        if csv_data is not None and not csv_data.empty:
            # Verificar que los datos cubren el per√≠odo solicitado
            if _data_covers_period(csv_data, start_date, end_date):
                logger.info(f"‚úÖ Datos encontrados en CSV para {symbol}: {len(csv_data)} filas")
                # Guardar en SQLite para futuras consultas
                try:
                    storage.save_data(csv_data, symbol, timeframe)
                    logger.info(f"üíæ Datos CSV guardados en SQLite para {symbol}")
                except Exception as e:
                    logger.warning(f"No se pudo guardar CSV en SQLite: {e}")
                return csv_data
            else:
                logger.warning(f"‚ö†Ô∏è Datos en CSV incompletos para {symbol}, descargando datos adicionales")
    except Exception as e:
        logger.warning(f"Error verificando CSV para {symbol}: {e}")
    
    # 3. TERCERO: Descargar autom√°ticamente si no existen datos
    logger.info(f"üîÑ Descargando datos autom√°ticamente para {symbol} ({start_date} ‚Üí {end_date})")
    
    try:
        downloaded_data = await _download_symbol_data(symbol, timeframe, start_date, end_date, config)
        if downloaded_data is not None and not downloaded_data.empty:
            logger.info(f"‚úÖ Datos descargados exitosamente para {symbol}: {len(downloaded_data)} filas")
            return downloaded_data
        else:
            raise Exception(f"No se pudieron descargar datos para {symbol}")
    except Exception as e:
        logger.error(f"‚ùå Error descargando datos para {symbol}: {e}")
        raise Exception(f"No se pudieron obtener datos para {symbol}: {e}")

def _data_covers_period(data: pd.DataFrame, start_date: str, end_date: str) -> bool:
    """Verifica si los datos cubren el per√≠odo solicitado"""
    try:
        if data.empty or 'timestamp' not in data.columns:
            return False
        
        data_start = pd.to_datetime(data['timestamp'].min()).strftime('%Y-%m-%d')
        data_end = pd.to_datetime(data['timestamp'].max()).strftime('%Y-%m-%d')
        
        return data_start <= start_date and data_end >= end_date
    except Exception:
        return False

def _load_csv_data(symbol: str, timeframe: str) -> Optional[pd.DataFrame]:
    """Carga datos desde archivo CSV"""
    try:
        import os
        from pathlib import Path
        
        csv_filename = f"{symbol.replace('/', '_')}_{timeframe}.csv"
        csv_path = Path(__file__).parent.parent / 'data' / 'csv' / csv_filename
        
        if csv_path.exists():
            df = pd.read_csv(csv_path)
            if not df.empty and 'timestamp' in df.columns:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                df.set_index('timestamp', inplace=True)
                return df
        
        return None
    except Exception as e:
        logger.warning(f"Error cargando CSV para {symbol}: {e}")
        return None

async def _download_symbol_data(symbol: str, timeframe: str, start_date: str, 
                              end_date: str, config: dict) -> Optional[pd.DataFrame]:
    """Descarga datos para un s√≠mbolo espec√≠fico"""
    try:
        from core.downloader import AdvancedDataDownloader
        
        downloader = AdvancedDataDownloader(config)
        # Inicializar el downloader (necesario para configurar exchanges)
        await downloader.initialize()
        
        # Determinar el tipo de descarga basado en el s√≠mbolo
        if symbol in ['SOL/USDT', 'ETH/USDT', 'BTC/USDT', 'ADA/USD', 'DOT/USD', 
                     'MATIC/USD', 'XRP/USDT', 'LTC/USD', 'DOGE/USDT']:
            # Descarga CCXT para criptomonedas
            downloaded_data = await downloader.download_multiple_symbols([symbol], timeframe, start_date, end_date)
            data = downloaded_data.get(symbol) if downloaded_data else None
        else:
            # Descarga MT5 para acciones y forex
            downloaded_data = await downloader.download_multiple_symbols([symbol], timeframe, start_date, end_date)
            data = downloaded_data.get(symbol) if downloaded_data else None
        
        if data is not None and not data.empty:
            # Guardar autom√°ticamente en SQLite
            storage = DataStorage()
            storage.save_data(data, symbol, timeframe)
            logger.info(f"üíæ Datos descargados guardados en SQLite para {symbol}")
            
            return data
        
        return None
    except Exception as e:
        logger.error(f"Error en descarga autom√°tica para {symbol}: {e}")
        return None