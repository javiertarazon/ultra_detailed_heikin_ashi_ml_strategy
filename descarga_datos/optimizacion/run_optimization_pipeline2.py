#!/usr/bin/env python3
"""
Pipeline de OptimizaciÃ³n Completo para UltraDetailedHeikinAshi

Este script implementa el pipeline completo de optimizaciÃ³n:
1. Entrena modelos ML con datos histÃ³ricos
2. Optimiza parÃ¡metros de la estrategia con Optuna
3. Ejecuta un backtest final con los mejores parÃ¡metros

Pasos:
- Entrenamiento ML: 2024 H1 (train), 2024 H2 (validation)
- OptimizaciÃ³n: 2024 completo (datos especÃ­ficos de optimizaciÃ³n)
- Backtest final: Mejor configuraciÃ³n en todo 2024
"""

import sys, os
# AÃ±adir el directorio padre (descarga_datos) al path para importar mÃ³dulos
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, parent_dir)

import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
import json
import time
from typing import Dict, List, Tuple
import dataclasses

from config.config_loader import load_config_from_yaml
# Importaciones lazy para evitar KeyboardInterrupt en Python 3.13
# from ml_trainer import MLTrainer  # Importado solo cuando se necesita
# from strategy_optimizer import StrategyOptimizer  # Importado solo cuando se necesita
from strategies.ultra_detailed_heikin_ashi_ml_strategy import UltraDetailedHeikinAshiMLStrategy
from utils.logger import setup_logger

logger = setup_logger(__name__)


class OptimizationPipeline:
    def __init__(self,
                 symbols=None,
                 timeframe="4h",
                 train_start="2022-01-01",
                 train_end="2023-06-30",
                 val_start="2022-07-01",
                 val_end="2023-12-31",
                 opt_start="2022-01-01",
                 opt_end="2023-12-31",
                 n_trials=50):
        """
        Inicializa el pipeline de optimizaciÃ³n completo.

        Args:
            symbols: Lista de sÃ­mbolos a procesar
            timeframe: Timeframe para los datos
            train_start/end: PerÃ­odo de entrenamiento ML
            val_start/end: PerÃ­odo de validaciÃ³n ML
            opt_start/end: PerÃ­odo para optimizaciÃ³n
            n_trials: NÃºmero de pruebas para Optuna
        """
        self.symbols = symbols if symbols else ["BTC/USDT"]
        self.timeframe = timeframe
        self.train_start = train_start
        self.train_end = train_end
        self.val_start = val_start
        self.val_end = val_end
        self.opt_start = opt_start
        self.opt_end = opt_end
        self.n_trials = n_trials

        # Cargar configuraciÃ³n
        self.config = load_config_from_yaml()
        logger.info(f"Pipeline inicializado para sÃ­mbolos: {self.symbols}")
        logger.info(f"Timeframe: {timeframe}, Trials: {n_trials}")

    async def run_complete_pipeline(self):
        """
        Ejecuta el pipeline completo de optimizaciÃ³n para todos los sÃ­mbolos.
        """
        start_time = time.time()
        pipeline_results = {}

        for symbol in self.symbols:
            try:
                symbol_start = time.time()
                logger.info(f"=== INICIANDO PIPELINE PARA {symbol} ===")

                # Paso 1: Entrenamiento ML (opcional en modo seguro)
                await self._train_ml_models(symbol)

                # Paso 2: OptimizaciÃ³n de parÃ¡metros
                opt_results = self._optimize_strategy_parameters(symbol)

                # Paso 3: Backtest final con mejores parÃ¡metros
                backtest_results = self._run_final_backtest(symbol, opt_results)

                # Guardar resultados de este sÃ­mbolo
                pipeline_results[symbol] = {
                    "optimization_results": opt_results,
                    "backtest_results": backtest_results,
                    "execution_time": time.time() - symbol_start
                }

                logger.info(f"Pipeline para {symbol} completado en {(time.time() - symbol_start)/60:.2f} minutos")

            except Exception as e:
                logger.error(f"Error en el pipeline para {symbol}: {e}")
                import traceback
                traceback.print_exc()

        # Guardar resultados completos
        self._save_pipeline_results(pipeline_results)

        total_time = time.time() - start_time
        logger.info(f"Pipeline completo finalizado en {total_time/60:.2f} minutos")

        return pipeline_results

    async def _train_ml_models(self, symbol):
        """
        Entrena los modelos ML para el sÃ­mbolo dado.

        Args:
            symbol (str): SÃ­mbolo a entrenar
        """
        logger.info(f"Iniciando entrenamiento ML para {symbol}")

        # Verificar si estÃ¡ en modo seguro (Python 3.13 compatibility)
        safe_mode = False
        if hasattr(self.config, 'ml_training'):
            ml_training = self.config.ml_training
            if hasattr(ml_training, 'safe_mode'):
                safe_mode = ml_training.safe_mode
        
        if safe_mode:
            logger.info("ðŸ›¡ï¸ MODO SEGURO ACTIVADO - Saltando entrenamiento ML")
            logger.info("Los modelos ML existentes serÃ¡n usados si estÃ¡n disponibles")
            return {
                'ml_training_completed': False,
                'safe_mode': True,
                'message': 'Modo seguro activado - usando modelos existentes o sin ML'
            }

        # ImportaciÃ³n lazy de MLTrainer para evitar KeyboardInterrupt en Python 3.13
        try:
            from .ml_trainer import MLTrainer
            logger.info("MLTrainer importado correctamente")
        except KeyboardInterrupt:
            logger.error("KeyboardInterrupt durante importaciÃ³n de MLTrainer")
            logger.error("Esto puede deberse a problemas de compatibilidad con Python 3.13 y sklearn")
            raise RuntimeError("No se puede importar MLTrainer. Considere usar Python 3.11 para ML")

        # Crear instancia del entrenador ML
        trainer = MLTrainer(symbol, self.timeframe)
        trainer.train_start = self.train_start
        trainer.train_end = self.train_end
        trainer.val_start = self.val_start
        trainer.val_end = self.val_end

        # Ejecutar entrenamiento
        try:
            training_results = await trainer.run()
            logger.info(f"Entrenamiento ML completado para {symbol}")
            return training_results
        except Exception as e:
            logger.error(f"Error durante entrenamiento ML: {e}")
            raise

    def _optimize_strategy_parameters(self, symbol, n_trials=None):
        """
        Optimiza los parÃ¡metros de la estrategia usando Optuna.

        Args:
            symbol (str): SÃ­mbolo a optimizar
            n_trials (int): NÃºmero de trials (opcional)

        Returns:
            dict: Resultados de la optimizaciÃ³n
        """
        if n_trials is None:
            n_trials = self.n_trials

        logger.info(f"Iniciando optimizaciÃ³n de parÃ¡metros para {symbol} con {n_trials} trials")

        # ImportaciÃ³n lazy de StrategyOptimizer
        try:
            from .strategy_optimizer import StrategyOptimizer
            logger.info("StrategyOptimizer importado correctamente")
        except ImportError as e:
            logger.error(f"No se puede importar StrategyOptimizer: {e}")
            # Fallback: devolver parÃ¡metros por defecto en formato correcto (None, [])
            return None, []

        # Crear optimizador
        optimizer = StrategyOptimizer(
            symbol=symbol,
            timeframe=self.timeframe,
            start_date=self.opt_start,
            end_date=self.opt_end,
            n_trials=n_trials
        )

        # Ejecutar optimizaciÃ³n
        try:
            opt_results = optimizer.run_optimization()
            logger.info(f"OptimizaciÃ³n completada para {symbol}")
            return opt_results
        except Exception as e:
            logger.error(f"Error durante optimizaciÃ³n: {e}")
            # Fallback: devolver parÃ¡metros por defecto en formato correcto
            return None, []

    def _run_final_backtest(self, symbol, opt_results):
        """
        Ejecuta el backtest final con los mejores parÃ¡metros.

        Args:
            symbol (str): SÃ­mbolo a testear
            opt_results (tuple): Tupla (study, pareto_trials) de optimizaciÃ³n

        Returns:
            dict: Resultados del backtest
        """
        logger.info(f"Ejecutando backtest final para {symbol}")

        # Verificar que opt_results sea vÃ¡lido
        if opt_results is None or not isinstance(opt_results, tuple):
            logger.error(f"opt_results invÃ¡lido: {opt_results}")
            return {
                "error": "No se pudo realizar optimizaciÃ³n - parÃ¡metros invÃ¡lidos",
                "symbol": symbol
            }

        # Extraer mejores parÃ¡metros del frente de Pareto
        study, pareto_trials = opt_results
        if pareto_trials and len(pareto_trials) > 0:
            best_trial = pareto_trials[0]  # Tomar el primer trial del frente de Pareto
            best_params = best_trial.params
            logger.info(f"Mejores parÃ¡metros encontrados: {best_params}")
        else:
            logger.warning("No se encontraron trials en el frente de Pareto, usando parÃ¡metros por defecto")
            best_params = {}

        # Crear estrategia con parÃ¡metros optimizados
        if isinstance(self.config, dict):
            strategy_config = self.config.copy()
            strategy_config.update(best_params)
        else:
            # Es un objeto Config - convertir a dict y actualizar
            strategy_config = dataclasses.asdict(self.config)
            strategy_config.update(best_params)

        strategy = UltraDetailedHeikinAshiMLStrategy(config=strategy_config)

        # ACTIVAR MODO OPTIMIZACIÃ“N para evitar re-entrenamiento ML durante backtest final
        strategy._optimization_mode = True

        # Cargar datos para backtest desde SQLite (SOLO DATOS REALES)
        logger.info("Cargando datos para backtest final desde base de datos...")

        # Importar StorageManager para acceder a datos reales
        from utils.storage import DataStorage
        
        # Crear conexiÃ³n a la base de datos
        storage = DataStorage(db_path=f"{self.config.storage.path}/data.db")
        
        # Convertir fechas a timestamps
        start_ts = int(pd.Timestamp(self.opt_start).timestamp()) if self.opt_start else None
        end_ts = int(pd.Timestamp(self.opt_end).timestamp()) if self.opt_end else None
        
        # Tabla para el sÃ­mbolo y timeframe
        table_name = f"{symbol.replace('/', '_')}_{self.timeframe}"
        
        # Cargar datos reales desde SQLite
        data = storage.query_data(table_name, start_ts=start_ts, end_ts=end_ts)
        
        if data is None or data.empty:
            logger.error(f"âŒ No se encontraron datos reales para {symbol} en el perÃ­odo de optimizaciÃ³n")
            return {
                "error": f"No hay datos disponibles para {symbol} en perÃ­odo {self.opt_start} a {self.opt_end}",
                "status": "error"
            }

        # Asegurar high >= max(open, close) y low <= min(open, close)
        data['high'] = np.maximum(data[['open', 'close']].max(axis=1), data['high'])
        data['low'] = np.minimum(data[['open', 'close']].min(axis=1), data['low'])

        # Ejecutar backtest
        try:
            backtest_results = strategy.run(data, symbol, self.timeframe)
            logger.info(f"Backtest final completado para {symbol}")
            return backtest_results
        except Exception as e:
            logger.error(f"Error durante backtest final: {e}")
            raise

    def _get_default_parameters(self, symbol):
        """
        Devuelve parÃ¡metros por defecto cuando la optimizaciÃ³n falla.

        Args:
            symbol (str): SÃ­mbolo

        Returns:
            dict: ParÃ¡metros por defecto
        """
        return {
            'best_params': {
                'ml_threshold': 0.7,
                'stoch_overbought': 85,
                'stoch_oversold': 15
            },
            'best_value': 0.0,
            'optimization_completed': False,
            'fallback': True
        }

    def _save_pipeline_results(self, results):
        """
        Guarda los resultados del pipeline completo.

        Args:
            results (dict): Resultados a guardar
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_dir = Path("descarga_datos/data/optimization_pipeline")
        results_dir.mkdir(parents=True, exist_ok=True)

        results_file = results_dir / f"pipeline_complete_{timestamp}.json"

        try:
            with open(results_file, 'w') as f:
                json.dump(results, f, indent=2, default=str)
            logger.info(f"Resultados del pipeline guardados en: {results_file}")
        except Exception as e:
            logger.error(f"Error guardando resultados: {e}")

    def run_quick_test(self):
        """
        Ejecuta un test rÃ¡pido del pipeline con 5 trials por sÃ­mbolo
        """
        logger.info("ðŸš€ Iniciando test rÃ¡pido del pipeline de optimizaciÃ³n")

        start_time = time.time()
        test_results = {}

        for symbol in self.symbols:
            logger.info(f"Test rÃ¡pido para {symbol}")
            symbol_start = time.time()

            try:
                # Paso 1: Entrenamiento ML rÃ¡pido
                self._train_ml_models(symbol)

                # Paso 2: OptimizaciÃ³n con solo 5 trials
                opt_results = self._optimize_strategy_parameters(symbol, n_trials=5)

                # Paso 3: Backtest final con mejores parÃ¡metros
                backtest_results = self._run_final_backtest(symbol, opt_results)

                test_results[symbol] = {
                    "optimization_results": opt_results,
                    "backtest_results": backtest_results,
                    "execution_time": time.time() - symbol_start
                }

                logger.info(f"Test rÃ¡pido para {symbol} completado en {(time.time() - symbol_start)/60:.2f} minutos")

            except Exception as e:
                logger.error(f"Error en test rÃ¡pido para {symbol}: {e}")
                import traceback
                traceback.print_exc()

        # Guardar resultados del test
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_dir = Path("descarga_datos/data/optimization_pipeline")
        results_dir.mkdir(parents=True, exist_ok=True)

        test_file = results_dir / f"quick_test_{timestamp}.json"

        try:
            with open(test_file, 'w') as f:
                json.dump(test_results, f, indent=2, default=str)
            logger.info(f"Resultados del test rÃ¡pido guardados en: {test_file}")
        except Exception as e:
            logger.error(f"Error guardando resultados del test: {e}")

        total_time = time.time() - start_time
        logger.info(f"Test rÃ¡pido completado en {total_time/60:.2f} minutos")

        return test_results


async def main():
    """
    FunciÃ³n principal para ejecutar el pipeline desde lÃ­nea de comandos.
    """
    import argparse

    parser = argparse.ArgumentParser(description='Pipeline de OptimizaciÃ³n Completo')
    parser.add_argument('--symbols', nargs='+', default=['SOL/USDT'],
                        help='SÃ­mbolos a optimizar')
    parser.add_argument('--timeframe', default='4h',
                        help='Timeframe para los datos')
    parser.add_argument('--trials', type=int, default=50,
                        help='NÃºmero de trials para optimizaciÃ³n')
    parser.add_argument('--quick-test', action='store_true',
                        help='Ejecutar test rÃ¡pido con 5 trials')

    args = parser.parse_args()

    pipeline = OptimizationPipeline(
        symbols=args.symbols,
        timeframe=args.timeframe,
        train_start="2025-01-01",
        train_end="2025-06-30",
        val_start="2025-07-01",
        val_end="2025-08-31",
        opt_start="2025-01-01",
        opt_end="2025-08-31",
        n_trials=args.trials
    )

    # Ejecutar pipeline
    try:
        if args.quick_test:
            results = pipeline.run_quick_test()
        else:
            results = await pipeline.run_complete_pipeline()

        logger.info("Pipeline ejecutado exitosamente")
        return results

    except Exception as e:
        logger.error(f"Error ejecutando pipeline: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
