#!/usr/bin/env python3
"""
ü§ñ Bot Trader Copilot - Sistema de Backtesting Masivo
======================================================

Sistema centralizado para ejecutar backtesting de m√∫ltiples s√≠mbolos
con configuraci√≥n flexible de per√≠odo, temporalidad y estrategias.

Caracter√≠sticas:
- Soporte para acciones (MT5) y criptomonedas (CCXT)
- Configuraci√≥n centralizada de s√≠mbolos y par√°metros
- Backtesting masivo con m√∫ltiples estrategias
- Reportes detallados y comparaci√≥n de resultados
"""

import asyncio
import pandas as pd
from datetime import datetime
import os
import sys
import subprocess
import time
import webbrowser
import socket
import json
from pathlib import Path

try:
    import requests
except ImportError:
    requests = None

# Agregar el directorio del proyecto al path
project_root = os.path.dirname(os.path.abspath(__file__))
parent_root = os.path.dirname(project_root)  # Carpeta padre
grandparent_root = os.path.dirname(parent_root)  # Carpeta abuelo donde est√° dash2.py
sys.path.append(project_root)
sys.path.append(parent_root)
sys.path.append(grandparent_root)

from core.downloader import AdvancedDataDownloader
from indicators.technical_indicators import TechnicalIndicators
from utils.normalization import DataNormalizer
from utils.storage import DataStorage, save_to_csv
from config.config_loader import load_config_from_yaml, get_active_exchanges, get_enabled_strategies
from utils.logger import setup_logging, get_logger
from strategies.ut_bot_psar import UTBotPSARStrategy
from strategies.optimized_utbot_strategy import OptimizedUTBotStrategy
from backtesting.backtester import AdvancedBacktester

def check_python_processes(logger=None):
    """
    Verifica si hay procesos Python ejecut√°ndose que puedan interferir.
    """
    try:
        import subprocess
        # Obtener todos los procesos Python con informaci√≥n detallada
        result = subprocess.run(['tasklist', '/FI', 'IMAGENAME eq python.exe', '/V'],
                              capture_output=True, text=True)

        python_processes = []
        lines = result.stdout.split('\n')

        for line in lines[3:]:  # Saltar encabezados
            if line.strip() and 'python.exe' in line.lower():
                parts = line.split()
                if len(parts) >= 2:
                    try:
                        pid = parts[1]
                        # Solo agregar PIDs v√°lidos
                        if pid.isdigit():
                            python_processes.append(pid)
                    except (ValueError, IndexError):
                        continue

        # Tambi√©n verificar procesos que podr√≠an estar usando el puerto 8501
        try:
            netstat_result = subprocess.run(['netstat', '-ano'], capture_output=True, text=True)
            for line in netstat_result.stdout.split('\n'):
                if ':8501' in line and 'LISTENING' in line:
                    parts = line.split()
                    if len(parts) >= 5:
                        pid = parts[-1]
                        if pid.isdigit() and pid not in python_processes:
                            python_processes.append(pid)
                            if logger:
                                logger.info(f"üîç Proceso usando puerto 8501 encontrado: PID {pid}")
        except Exception as e:
            if logger:
                logger.warning(f"No se pudo verificar procesos en puerto 8501: {e}")

        if python_processes:
            if logger:
                logger.info(f"üîç Encontrados {len(python_processes)} procesos Python: {', '.join(python_processes)}")
            return python_processes
        else:
            if logger:
                logger.info("‚úÖ No hay procesos Python conflictivos")
            return []

    except Exception as e:
        if logger:
            logger.warning(f"No se pudo verificar procesos Python: {e}")
        return []

def check_streamlit_processes(logger=None):
    """
    Verifica espec√≠ficamente procesos de Streamlit que puedan estar ejecut√°ndose.
    """
    try:
        import subprocess
        # Buscar procesos que contengan "streamlit" en el comando
        result = subprocess.run(['tasklist', '/FI', 'IMAGENAME eq python.exe', '/V'],
                              capture_output=True, text=True)

        streamlit_processes = []
        lines = result.stdout.split('\n')

        for line in lines:
            if 'streamlit' in line.lower():
                # Extraer PID de la l√≠nea
                parts = line.split()
                if len(parts) > 1:
                    try:
                        pid = parts[1]
                        streamlit_processes.append(pid)
                    except (ValueError, IndexError):
                        continue

        if streamlit_processes:
            if logger:
                logger.info(f"üîç Encontrados {len(streamlit_processes)} procesos Streamlit: {', '.join(streamlit_processes)}")
            return streamlit_processes
        else:
            if logger:
                logger.info("‚úÖ No hay procesos Streamlit ejecut√°ndose")
            return []

    except Exception as e:
        if logger:
            logger.warning(f"No se pudo verificar procesos Streamlit: {e}")
        return []

def check_port_availability(port=8501, logger=None):
    """
    Verifica si el puerto especificado est√° disponible.
    """
    try:
        import socket
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(5)  # Timeout de 5 segundos

        result = sock.connect_ex(('localhost', port))
        sock.close()

        if result == 0:
            if logger:
                logger.warning(f"‚ö†Ô∏è Puerto {port} est√° ocupado")
            return False
        else:
            if logger:
                logger.info(f"‚úÖ Puerto {port} est√° disponible")
            return True

    except socket.timeout:
        if logger:
            logger.warning(f"Timeout verificando puerto {port}")
        return False
    except Exception as e:
        if logger:
            logger.warning(f"No se pudo verificar puerto {port}: {e}")
        return True  # Asumir disponible si no se puede verificar

def kill_conflicting_processes(processes, logger=None):
    """
    Mata procesos conflictivos de Python.
    """
    try:
        import subprocess
        killed_count = 0
        failed_count = 0

        for pid in processes:
            try:
                # Usar taskkill con m√°s opciones para asegurar terminaci√≥n
                result = subprocess.run(['taskkill', '/PID', str(pid), '/F', '/T'],
                                      capture_output=True, text=True, timeout=10)

                if result.returncode == 0:
                    killed_count += 1
                    if logger:
                        logger.info(f"üõë Proceso Python {pid} terminado exitosamente")
                else:
                    failed_count += 1
                    if logger:
                        logger.warning(f"No se pudo terminar proceso {pid}: {result.stderr}")

            except subprocess.TimeoutExpired:
                failed_count += 1
                if logger:
                    logger.warning(f"Timeout terminando proceso {pid}")
            except Exception as e:
                failed_count += 1
                if logger:
                    logger.warning(f"Error terminando proceso {pid}: {e}")

        if logger:
            if killed_count > 0:
                logger.info(f"‚úÖ Terminados {killed_count} procesos conflictivos exitosamente")
            if failed_count > 0:
                logger.warning(f"‚ö†Ô∏è No se pudieron terminar {failed_count} procesos")

        return killed_count

    except Exception as e:
        if logger:
            logger.error(f"Error general terminando procesos: {e}")
        return 0

def force_cleanup_port_8501(logger=None):
    """
    Fuerza la liberaci√≥n del puerto 8501 usando comandos del sistema operativo.
    """
    try:
        import subprocess

        success = False

        # M√©todo 1: Usar netstat y taskkill para encontrar y matar procesos usando el puerto
        try:
            logger.info("üîß M√©todo 1: Liberando puerto usando netstat + taskkill...")

            # Encontrar procesos usando el puerto 8501
            netstat_result = subprocess.run(['netstat', '-ano'], capture_output=True, text=True, timeout=10)

            pids_to_kill = []
            for line in netstat_result.stdout.split('\n'):
                if ':8501' in line and ('LISTENING' in line or 'ESTABLISHED' in line):
                    parts = line.split()
                    if len(parts) >= 5:
                        pid = parts[-1]
                        if pid.isdigit() and pid not in pids_to_kill:
                            pids_to_kill.append(pid)

            # Matar los procesos encontrados
            for pid in pids_to_kill:
                try:
                    result = subprocess.run(['taskkill', '/PID', pid, '/F', '/T'],
                                          capture_output=True, text=True, timeout=5)
                    if result.returncode == 0:
                        if logger:
                            logger.info(f"üõë Proceso {pid} (usando puerto 8501) terminado")
                        success = True
                    else:
                        if logger:
                            logger.warning(f"No se pudo terminar proceso {pid}: {result.stderr}")
                except Exception as e:
                    if logger:
                        logger.warning(f"Error terminando proceso {pid}: {e}")

        except Exception as e:
            if logger:
                logger.warning(f"Error en m√©todo 1: {e}")

        # M√©todo 2: Matar todos los procesos de Python (m√°s agresivo)
        try:
            if not success:
                logger.info("üîß M√©todo 2: Terminando todos los procesos Python...")

                result = subprocess.run(['taskkill', '/IM', 'python.exe', '/F'],
                                      capture_output=True, text=True, timeout=10)

                if result.returncode == 0:
                    if logger:
                        logger.info("üõë Todos los procesos Python terminados")
                    success = True
                    time.sleep(3)  # Esperar a que se liberen los recursos
                else:
                    if logger:
                        logger.warning(f"No se pudieron terminar procesos Python: {result.stderr}")

        except Exception as e:
            if logger:
                logger.warning(f"Error en m√©todo 2: {e}")

        # M√©todo 3: Usar comandos de red para forzar liberaci√≥n
        try:
            if not success:
                logger.info("üîß M√©todo 3: Usando comandos de red para liberar puerto...")

                # En Windows, intentar resetear el puerto
                result = subprocess.run(['netsh', 'interface', 'ipv4', 'reset'],
                                      capture_output=True, text=True, timeout=15)

                if result.returncode == 0:
                    if logger:
                        logger.info("üîÑ Interfaces de red reseteadas")
                    success = True
                    time.sleep(2)
                else:
                    if logger:
                        logger.warning(f"No se pudieron resetear interfaces: {result.stderr}")

        except Exception as e:
            if logger:
                logger.warning(f"Error en m√©todo 3: {e}")

        # Verificaci√≥n final
        time.sleep(2)
        final_check = check_port_availability(8501, logger)

        if final_check:
            if logger:
                logger.info("‚úÖ Puerto 8501 liberado exitosamente")
            return True
        else:
            if logger:
                logger.warning("‚ö†Ô∏è Puerto 8501 a√∫n ocupado despu√©s de limpieza")
            return False

    except Exception as e:
        if logger:
            logger.error(f"‚ùå Error en limpieza forzada del puerto: {e}")
        return False

def verify_dashboard_running(logger=None):
    """
    Verifica que el dashboard est√© realmente ejecut√°ndose y respondiendo.
    """
    try:
        max_attempts = 5
        for attempt in range(max_attempts):
            try:
                if requests:
                    # Usar requests si est√° disponible
                    response = requests.get("http://localhost:8501", timeout=5)
                    if response.status_code == 200:
                        if logger:
                            logger.info("‚úÖ Dashboard respondiendo correctamente")
                        return True
                else:
                    # Usar socket como alternativa
                    import socket
                    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                    sock.settimeout(5)
                    result = sock.connect_ex(('localhost', 8501))
                    sock.close()
                    if result == 0:
                        if logger:
                            logger.info("‚úÖ Dashboard respondiendo correctamente (verificaci√≥n socket)")
                        return True

            except Exception as e:
                if logger:
                    logger.debug(f"Intento {attempt + 1} fall√≥: {e}")
                pass

            if logger:
                logger.info(f"‚è≥ Esperando respuesta del dashboard (intento {attempt + 1}/{max_attempts})...")
            time.sleep(2)

        if logger:
            logger.warning("‚ö†Ô∏è Dashboard no responde despu√©s de m√∫ltiples intentos")
        return False

    except Exception as e:
        if logger:
            logger.warning(f"Error verificando dashboard: {e}")
        return False

def launch_dashboard():
    """
    Lanza el dashboard profesional con limpieza autom√°tica agresiva de puertos.
    """
    try:
        logger = get_logger(__name__)
        logger.info("üöÄ Iniciando verificaci√≥n previa al lanzamiento del dashboard...")

        # PASO 1: Limpieza agresiva del puerto 8501
        logger.info("üßπ Realizando limpieza agresiva del puerto 8501...")
        success = force_cleanup_port_8501(logger)
        if not success:
            logger.warning("‚ö†Ô∏è No se pudo liberar completamente el puerto, intentando continuar...")

        # PASO 2: Verificar procesos Python existentes
        logger.info("üîç Verificando procesos Python existentes...")
        python_processes = check_python_processes(logger)

        # PASO 3: Verificar procesos Streamlit espec√≠ficamente
        logger.info("üîç Verificando procesos Streamlit existentes...")
        streamlit_processes = check_streamlit_processes(logger)

        # PASO 4: Combinar listas de procesos a terminar
        all_processes = list(set(python_processes + streamlit_processes))

        # PASO 5: Verificar disponibilidad del puerto con m√∫ltiples intentos
        logger.info("üîç Verificando disponibilidad del puerto 8501...")
        port_available = False
        max_attempts = 3

        for attempt in range(max_attempts):
            port_available = check_port_availability(8501, logger)

            if port_available:
                logger.info("‚úÖ Puerto 8501 disponible")
                break
            else:
                logger.warning(f"‚ö†Ô∏è Puerto ocupado (intento {attempt + 1}/{max_attempts})")

                if all_processes:
                    logger.info("üõë Intentando terminar procesos conflictivos...")
                    killed_count = kill_conflicting_processes(all_processes, logger)

                    if killed_count > 0:
                        logger.info(f"‚è≥ Esperando {10 + attempt * 5} segundos para que los procesos terminen...")
                        time.sleep(10 + attempt * 5)  # Esperar m√°s tiempo en cada intento
                    else:
                        logger.warning("‚ùå No se pudieron terminar procesos, intentando forzar liberaci√≥n del puerto...")
                        force_cleanup_port_8501(logger)
                        time.sleep(5)
                else:
                    logger.info("üõë No hay procesos identificados, intentando forzar liberaci√≥n del puerto...")
                    force_cleanup_port_8501(logger)
                    time.sleep(5)

        if not port_available:
            logger.error("‚ùå No se pudo liberar el puerto 8501 despu√©s de m√∫ltiples intentos")
            logger.info("üí° Sugerencias:")
            logger.info("   1. Cierra manualmente otros procesos de Streamlit/Python")
            logger.info("   2. Reinicia tu computadora si es necesario")
            logger.info("   3. Verifica que no haya otras aplicaciones usando el puerto 8501")
            return False

        # PASO 6: Verificar que el dashboard existe
        dashboard_path = os.path.join(grandparent_root, "dash2.py")
        if not os.path.exists(dashboard_path):
            logger.error(f"‚ùå Dashboard no encontrado en: {dashboard_path}")
            return False

        logger.info("üìä Lanzando Dashboard Profesional...")

        # PASO 7: Ejecutar Streamlit con mejor manejo de errores
        try:
            import subprocess

            # Comando para ejecutar streamlit con opciones adicionales
            cmd = [
                sys.executable, "-m", "streamlit", "run", "dash2.py",
                "--server.port", "8501",
                "--server.headless", "true",
                "--server.address", "0.0.0.0",
                "--server.enableCORS", "false",
                "--server.enableXsrfProtection", "false"
            ]

            logger.info("üìä Ejecutando Streamlit directamente...")
            logger.info(f"üìÇ Directorio de trabajo: {grandparent_root}")
            logger.info(f"üìÑ Archivo dashboard: dash2.py")

            # Ejecutar streamlit en background con mejor configuraci√≥n
            process = subprocess.Popen(
                cmd,
                cwd=grandparent_root,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0
            )

            # Esperar m√°s tiempo para que se inicie completamente
            logger.info("‚è≥ Esperando que Streamlit se inicie completamente...")
            time.sleep(8)

            # Verificar si est√° ejecut√°ndose
            if process.poll() is None:
                logger.info("‚úÖ Dashboard iniciado correctamente")
                logger.info("üìä Dashboard disponible en: http://localhost:8501")

                # Verificar que realmente est√© respondiendo
                if verify_dashboard_running(logger):
                    # Abrir navegador
                    try:
                        import webbrowser
                        webbrowser.open("http://localhost:8501")
                        logger.info("üåê Navegador abierto autom√°ticamente")
                    except Exception as e:
                        logger.warning(f"No se pudo abrir navegador: {e}")

                    return True
                else:
                    logger.error("‚ùå Dashboard no responde correctamente")
                    process.terminate()
                    return False
            else:
                # Si fall√≥, obtener el error
                stdout, stderr = process.communicate()
                logger.error("‚ùå Error iniciando dashboard:")
                if stderr:
                    logger.error(f"STDERR: {stderr}")
                if stdout:
                    logger.info(f"STDOUT: {stdout}")
                return False

        except Exception as e:
            logger.error(f"‚ùå Error lanzando dashboard: {e}")
            return False

    except Exception as e:
        logger.error(f"‚ùå Error general en launch_dashboard: {e}")
        return False

def validate_data(df: pd.DataFrame, logger=None) -> bool:
    """
    Valida la integridad de los datos antes del backtesting.
    """
    if logger is None:
        logger = get_logger(__name__)

    if df.empty:
        logger.error("El DataFrame est√° vac√≠o")
        return False

    required_columns = ['open', 'high', 'low', 'close', 'volume']
    technical_columns = ['sar', 'atr', 'adx']
    all_required = required_columns + technical_columns

    missing_columns = [col for col in all_required if col not in df.columns]
    if missing_columns:
        logger.error(f"Faltan columnas requeridas: {missing_columns}")
        return False

    # Verificar valores nulos
    null_check = df[required_columns].isnull().any()
    if null_check.any():
        null_cols = null_check[null_check].index.tolist()
        logger.error(f"Hay valores nulos en las columnas OHLCV: {null_cols}")
        return False

    logger.info("Validaci√≥n de datos completada exitosamente")
    return True

async def download_symbol_data(symbol: str, config,
                             downloader, mt5_downloader, logger):
    """
    Descarga datos para un s√≠mbolo espec√≠fico usando la fuente apropiada.
    """
    timeframe = config.backtesting.timeframe
    start_date = config.backtesting.start_date
    end_date = config.backtesting.end_date

    try:
        if symbol.endswith('.US'):
            # Acci√≥n - usar MT5 si est√° disponible
            if mt5_downloader is not None:
                logger.info(f"[INFO] Descargando {symbol} desde MT5...")

                # Convertir fechas
                start_dt = datetime.strptime(start_date, '%Y-%m-%d')
                end_dt = datetime.strptime(end_date, '%Y-%m-%d')

                ohlcv_data = await mt5_downloader.download_data(
                    symbol.replace('.US', ''), timeframe, start_dt, end_dt
                )

                if ohlcv_data is not None and not ohlcv_data.empty:
                    logger.info(f"[SUCCESS] Datos descargados desde MT5: {len(ohlcv_data)} velas")
                    return ohlcv_data
                else:
                    logger.warning(f"[WARNING] No se pudieron descargar datos de MT5 para {symbol}")

        else:
            # Criptomoneda - usar CCXT
            logger.info(f"[INFO] Descargando {symbol} desde CCXT...")

            ohlcv_data, stats = await downloader.async_download_ohlcv(
                symbol, config.active_exchange, timeframe=timeframe, limit=1000
            )

            if ohlcv_data is not None and not ohlcv_data.empty:
                logger.info(f"[SUCCESS] Datos descargados desde CCXT: {len(ohlcv_data)} velas")
                return ohlcv_data
            else:
                logger.warning(f"[WARNING] No se pudieron descargar datos de CCXT para {symbol}")

    except Exception as e:
        logger.error(f"[ERROR] Error descargando {symbol}: {e}")

    return None

async def process_symbol_backtest(data: pd.DataFrame, symbol: str, config, logger) -> dict:
    """
    Procesa el backtesting completo para un s√≠mbolo con datos ya descargados.
    """
    try:
        if data is None or data.empty:
            logger.error(f"No hay datos disponibles para {symbol}")
            return {}

        # Los datos ya incluyen indicadores calculados y normalizados
        data_with_indicators = data

        # 1. Validar datos
        if not validate_data(data_with_indicators, logger):
            logger.error(f"Datos inv√°lidos para {symbol}")
            return {}

        # 2. Ejecutar backtesting
        logger.info(f"[INFO] Ejecutando backtesting para {symbol}...")
        results = await run_backtest(data_with_indicators, symbol, config)

        if results:
            logger.info(f"[SUCCESS] Backtesting completado exitosamente para {symbol}")
            
            # Guardar resultados para el dashboard
            print(f"[DEBUG] Llamando a save_backtest_results para {symbol}")
            await save_backtest_results(results, symbol, config, logger)
            
            return results
        else:
            logger.warning(f"[WARNING] Backtesting sin resultados para {symbol}")
            return {}

    except Exception as e:
        logger.error(f"[ERROR] Error procesando {symbol}: {e}")
        return {}

async def run_backtest(data: pd.DataFrame, symbol: str, config) -> dict:
    """
    Ejecuta el backtesting con la estrategia unificada usando diferentes estilos.
    """
    logger = get_logger(__name__)

    # Importar estrategias individuales
    from strategies.ut_bot_psar import UTBotPSARStrategy
    from strategies.ut_bot_psar_conservative import UTBotPSARConservativeStrategy
    from strategies.ut_bot_psar_optimized import UTBotPSAROptimizedStrategy

    # Configuraciones de estrategia basadas en la configuraci√≥n
    strategies = {}

    enabled_strategies = get_enabled_strategies(config)
    logger.info(f"[DEBUG] Estrategias habilitadas: {enabled_strategies}")
    logger.info(f"[DEBUG] N√∫mero de estrategias habilitadas: {len(enabled_strategies)}")

    # Crear estrategias individuales
    if "Estrategia_Basica" in enabled_strategies:
        strategies["Estrategia_Basica"] = UTBotPSARStrategy()

    if "Estrategia_Conservadora" in enabled_strategies:
        strategies["Estrategia_Conservadora"] = UTBotPSARConservativeStrategy()

    if "Estrategia_Optimizada" in enabled_strategies:
        strategies["Estrategia_Optimizada"] = UTBotPSAROptimizedStrategy()

    logger.info(f"[DEBUG] Estrategias configuradas: {list(strategies.keys())}")
    logger.info(f"[DEBUG] N√∫mero de estrategias configuradas: {len(strategies)}")

    results = {}

    for strategy_name, strategy in strategies.items():
        logger.info(f"[INFO] Probando estrategia: {strategy_name}")

        backtester = AdvancedBacktester(
            initial_capital=config.backtesting.initial_capital,
            commission=config.backtesting.commission
        )

        strategy_results = backtester.run(strategy, data, symbol)
        results[strategy_name] = strategy_results

        # Log b√°sico de resultados
        pnl = strategy_results.get('total_pnl', 0)
        win_rate = strategy_results.get('win_rate', 0) * 100
        logger.info(f"[SUCCESS] Backtesting completado para {symbol}: {len(strategy_results.get('trades', []))} trades, P&L: ${pnl:.2f}, Win Rate: {win_rate:.1f}%")

    return results

def generate_backtest_report(results: dict, config, logger):
    """
    Genera un reporte final del backtesting masivo.
    """
    logger.info(f"\n{'='*80}")
    logger.info("[INFO] REPORTE FINAL DE BACKTESTING MASIVO")
    logger.info(f"{'='*80}")

    if not results:
        logger.warning("No hay resultados para mostrar")
        return

    # An√°lisis por s√≠mbolo
    logger.info(f"\n[INFO] RESULTADOS POR SIMBOLO:")
    logger.info("-" * 80)
    logger.info(f"{'S√≠mbolo':15s} | {'Mejor Estrategia':20s} | {'P&L':10s} | {'Win Rate':8s} | {'Max DD':8s}")
    logger.info("-" * 80)

    symbol_summary = []
    for symbol, strategies in results.items():
        best_strategy = max(strategies.items(), key=lambda x: x[1].get('total_pnl', -10000))
        strategy_name, result = best_strategy

        pnl = result.get('total_pnl', 0)
        win_rate = result.get('win_rate', 0) * 100
        max_dd = result.get('max_drawdown', 0) * 100

        symbol_summary.append({
            'symbol': symbol,
            'strategy': strategy_name,
            'pnl': pnl,
            'win_rate': win_rate,
            'max_dd': max_dd
        })

        logger.info(f"{symbol:15s} | {strategy_name:20s} | ${pnl:10.2f} | {win_rate:6.1f}% | {max_dd:6.1f}%")

    # Ranking final
    logger.info(f"\n[INFO] RANKING FINAL (ordenado por P&L):")
    logger.info("-" * 80)
    logger.info(f"{'Posici√≥n':8s} | {'S√≠mbolo':10s} | {'Estrategia':20s} | {'P&L':10s} | {'Win Rate':8s}")
    logger.info("-" * 80)

    sorted_symbols = sorted(symbol_summary, key=lambda x: x['pnl'], reverse=True)

    for i, item in enumerate(sorted_symbols, 1):
        medal = "[1st]" if i == 1 else "[2nd]" if i == 2 else "[3rd]" if i == 3 else f"{i:2d}"
        logger.info(f"{medal} | {item['symbol']:10s} | {item['strategy']:20s} | ${item['pnl']:10.2f} | {item['win_rate']:6.1f}%")

    # Estad√≠sticas generales
    total_pnl = sum(item['pnl'] for item in symbol_summary)
    avg_win_rate = sum(item['win_rate'] for item in symbol_summary) / len(symbol_summary)
    profitable_symbols = sum(1 for item in symbol_summary if item['pnl'] > 0)

    logger.info(f"\n[INFO] ESTADISTICAS GENERALES:")
    logger.info(f"   ‚Ä¢ S√≠mbolos procesados: {len(symbol_summary)}")
    logger.info(f"   ‚Ä¢ S√≠mbolos rentables: {profitable_symbols}")
    logger.info(f"   ‚Ä¢ P&L Total: ${total_pnl:.2f}")
    logger.info(f"   ‚Ä¢ Win Rate Promedio: {avg_win_rate:.1f}%")
    logger.info(f"   ‚Ä¢ Temporalidad: {config.backtesting.timeframe}")
    logger.info(f"   ‚Ä¢ Periodo: {config.backtesting.start_date} a {config.backtesting.end_date}")

    # === SISTEMA DE COMPENSACI√ìN DESACTIVADO ===
    logger.info(f"\n[INFO] SISTEMA DE COMPENSACI√ìN: DESACTIVADO")
    logger.info(f"   ‚Ä¢ No se aplican compensaciones a los resultados")
    logger.info(f"   ‚Ä¢ Se muestran resultados puros de las estrategias")

    logger.info(f"\n{'='*80}")

async def main():
    """
    Funci√≥n principal del sistema de backtesting masivo.
    """
    # Cargar configuraci√≥n centralizada
    config = load_config_from_yaml()

    # Configurar logging
    setup_logging(config.system.log_level, config.system.log_file)
    logger = get_logger(__name__)

    logger.info("[INFO] Iniciando Bot Trader Copilot - Backtesting Masivo")
    logger.info("=" * 60)

    # Mostrar configuraci√≥n actual
    active_symbols = config.backtesting.symbols
    logger.info(f"[INFO] Simbolos a procesar: {len(active_symbols)}")
    logger.info(f"[INFO] Temporalidad: {config.backtesting.timeframe}")
    logger.info(f"[INFO] Periodo: {config.backtesting.start_date} a {config.backtesting.end_date}")
    logger.info(f"[INFO] Capital inicial: ${config.backtesting.initial_capital}")
    enabled_strategies = get_enabled_strategies(config)
    logger.info(f"[INFO] Estrategias activas: {len(enabled_strategies)}")
    logger.info("=" * 60)

    # Inicializar componentes
    downloader = AdvancedDataDownloader(config)

    # Verificar MT5
    mt5_available = False
    if config.mt5.enabled:
        logger.info("[INFO] MT5 habilitado - disponible para acciones")
        mt5_available = True
    else:
        logger.info("[INFO] MT5 deshabilitado - solo criptomonedas")

    storage = DataStorage(f"{config.storage.path}/data.db")
    backtest_results = {}

    try:
        # Inicializar downloader avanzado
        success = await downloader.initialize()
        if not success:
            logger.error("No se pudo inicializar el downloader")
            return

        # Descargar datos de todos los s√≠mbolos en paralelo
        logger.info("üöÄ Iniciando descarga masiva de datos...")
        symbol_data = await downloader.download_multiple_symbols(
            active_symbols,
            timeframe=config.backtesting.timeframe,
            start_date=config.backtesting.start_date,
            end_date=config.backtesting.end_date
        )

        if not symbol_data:
            logger.error("No se pudieron descargar datos de ning√∫n s√≠mbolo")
            return

        # Procesar y guardar datos
        logger.info("üíæ Procesando y guardando datos...")
        processed_symbol_data = await downloader.process_and_save_data(
            symbol_data,
            config.backtesting.timeframe,
            save_csv=True
        )

        # Procesar backtesting para cada s√≠mbolo
        backtest_results = {}
        for i, (symbol, df) in enumerate(processed_symbol_data.items(), 1):
            logger.info(f"\n{'='*60}")
            logger.info(f"Procesando backtesting {i}/{len(processed_symbol_data)}: {symbol}")
            logger.info(f"{'='*60}")

            result = await process_symbol_backtest(df, symbol, config, logger)
            if result:
                backtest_results[symbol] = result
                print(f"[DEBUG] Resultado guardado para {symbol}: {len(result)} estrategias")
            else:
                print(f"[DEBUG] No hay resultado para {symbol}")

        print(f"[DEBUG] Backtest completado. Total s√≠mbolos procesados: {len(backtest_results)}")
        # Generar reporte final
        generate_backtest_report(backtest_results, config, logger)

        # Guardar resumen global para el dashboard
        if backtest_results:
            await save_global_summary(backtest_results, config, logger)

        # Lanzar dashboard autom√°ticamente si est√° habilitado
        if hasattr(config.system, 'auto_launch_dashboard') and config.system.auto_launch_dashboard:
            logger.info("üìä Iniciando lanzamiento autom√°tico del dashboard...")
            dashboard_launched = launch_dashboard()
            if dashboard_launched:
                logger.info("‚úÖ Dashboard profesional iniciado exitosamente")
                logger.info("üåê Accede a: http://localhost:8501")
            else:
                logger.warning("‚ö†Ô∏è No se pudo iniciar el dashboard autom√°ticamente")
        else:
            logger.info("üìä Dashboard autom√°tico deshabilitado")
            logger.info("üí° Para ver los resultados, ejecuta: python run_dashboard.py")

    finally:
        # Cerrar conexiones
        await downloader.shutdown()

def calculate_symbol_compensation_metrics(results: dict, compensation_config: dict = None) -> dict:
    """
    Calcula m√©tricas de compensaci√≥n realistas basadas en configuraci√≥n.

    Args:
        results: Resultados del backtesting por estrategia
        compensation_config: Configuraci√≥n de compensaci√≥n (opcional)
    """
    if compensation_config is None:
        compensation_config = {
            'enabled': True,
            'success_rate': 0.65,  # 65% de √©xito en compensaciones
            'recovery_factor': 0.75,  # 75% de recuperaci√≥n de p√©rdida
            'max_compensation_size': 0.5,  # M√°ximo 50% del tama√±o original
            'min_trade_size': 10,  # M√≠nimo tama√±o de trade para compensar
            'max_daily_compensations': 3,  # M√°ximo compensaciones por d√≠a
            'cooldown_period': 2  # D√≠as de enfriamiento entre compensaciones
        }

    if not compensation_config.get('enabled', True):
        return {
            'compensated_trades': 0,
            'total_compensation_pnl': 0.0,
            'compensation_success_rate': 0.0,
            'adjusted_total_pnl': 0.0
        }

    print(f"[DEBUG] Funci√≥n calculate_symbol_compensation_metrics llamada con configuraci√≥n realista")
    logger = get_logger(__name__)
    logger.info(f"[DEBUG] Calculando m√©tricas de compensaci√≥n realistas")

    # Obtener la mejor estrategia para calcular m√©tricas
    best_strategy = max(results.items(), key=lambda x: x[1].get('total_pnl', -10000))
    strategy_name, result = best_strategy
    print(f"[DEBUG] Mejor estrategia: {strategy_name}")

    # Obtener trades de la mejor estrategia
    trades = result.get('trades', [])
    print(f"[DEBUG] N√∫mero total de trades: {len(trades)}")

    if not trades:
        return {
            'compensated_trades': 0,
            'total_compensation_pnl': 0.0,
            'compensation_success_rate': 0.0,
            'adjusted_total_pnl': result.get('total_pnl', 0)
        }

    # Filtrar trades perdedores elegibles para compensaci√≥n
    losing_trades = []
    for trade in trades:
        pnl = trade.get('pnl', 0)
        if pnl < 0:  # Trade perdedor
            # Verificar tama√±o m√≠nimo
            trade_size = abs(pnl)
            if trade_size >= compensation_config['min_trade_size']:
                losing_trades.append(trade)

    print(f"[DEBUG] Trades perdedores elegibles: {len(losing_trades)}")

    if not losing_trades:
        return {
            'compensated_trades': 0,
            'total_compensation_pnl': 0.0,
            'compensation_success_rate': 0.0,
            'adjusted_total_pnl': result.get('total_pnl', 0)
        }

    # Simular compensaciones realistas
    total_compensation_pnl = 0.0
    successful_compensations = 0
    compensation_attempts = 0

    # Procesar trades por fecha para respetar l√≠mites diarios
    trades_by_date = {}
    for trade in losing_trades:
        date = trade.get('entry_date', trade.get('date', 'unknown'))
        if date not in trades_by_date:
            trades_by_date[date] = []
        trades_by_date[date].append(trade)

    # Procesar d√≠a por d√≠a
    for date, day_trades in trades_by_date.items():
        daily_compensations = 0

        for trade in day_trades:
            if daily_compensations >= compensation_config['max_daily_compensations']:
                break  # L√≠mite diario alcanzado

            compensation_attempts += 1

            # Calcular tama√±o de compensaci√≥n (limitado)
            original_loss = abs(trade.get('pnl', 0))
            max_compensation = original_loss * compensation_config['max_compensation_size']
            compensation_size = min(max_compensation, original_loss * 0.3)  # M√°ximo 30% del original

            # Simular resultado de compensaci√≥n con probabilidad realista
            import random
            random.seed(hash(f"{date}_{compensation_attempts}"))  # Seed consistente
            compensation_success = random.random() < compensation_config['success_rate']

            if compensation_success:
                # Compensaci√≥n exitosa - recupera parte de la p√©rdida
                recovery_amount = compensation_size * compensation_config['recovery_factor']
                compensation_pnl = recovery_amount
                successful_compensations += 1
                daily_compensations += 1
            else:
                # Compensaci√≥n fallida - genera p√©rdida adicional peque√±a
                compensation_pnl = -compensation_size * 0.2  # Solo 20% de p√©rdida adicional

            total_compensation_pnl += compensation_pnl

    # Calcular m√©tricas finales
    total_losing_trades = len(losing_trades)
    compensation_success_rate = (successful_compensations / compensation_attempts) * 100 if compensation_attempts > 0 else 0
    original_pnl = result.get('total_pnl', 0)
    adjusted_total_pnl = original_pnl + total_compensation_pnl

    metrics = {
        'compensated_trades': successful_compensations,
        'total_compensation_pnl': total_compensation_pnl,
        'compensation_success_rate': compensation_success_rate,
        'adjusted_total_pnl': adjusted_total_pnl,
        'total_losing_trades': total_losing_trades,
        'compensation_attempts': compensation_attempts,
        'compensation_config': compensation_config
    }

    print(f"[DEBUG] M√©tricas calculadas: {metrics}")
    logger.info(f"[DEBUG] Compensaci√≥n completada: {successful_compensations}/{compensation_attempts} exitosas ({compensation_success_rate:.1f}%)")

    return metrics

async def save_backtest_results(results: dict, symbol: str, config, logger):
    print(f"[DEBUG] save_backtest_results llamada para {symbol} con {len(results)} estrategias")
    try:
        # Crear directorio para resultados si no existe
        results_dir = Path("data/dashboard_results")
        results_dir.mkdir(parents=True, exist_ok=True)

        # Archivo para este s√≠mbolo
        results_file = results_dir / f"{symbol.replace('/', '_').replace('.', '_')}_results.json"

        # Preparar datos para guardar
        dashboard_data = {
            'symbol': symbol,
            'timestamp': datetime.now().isoformat(),
            'strategies': {},
            'summary': {
                'total_strategies': len(results),
                'best_strategy': None,
                'best_pnl': float('-inf'),
                'total_trades': 0,
                'avg_win_rate': 0.0,
                'total_compensated_trades': 0,
                'total_compensation_pnl': 0.0,
                'avg_compensation_rate': 0.0
            }
        }

        win_rates = []
        compensation_rates = []

        # === SISTEMA DE COMPENSACI√ìN COMPLETAMENTE DESACTIVADO ===
        logger.info(f"[INFO] Sistema de compensaci√≥n completamente deshabilitado para {symbol}")

        for strategy_name, strategy_result in results.items():
            # Convertir datos no serializables
            clean_result = {}
            for key, value in strategy_result.items():
                if isinstance(value, pd.Series):
                    clean_result[key] = value.tolist()
                elif isinstance(value, pd.DataFrame):
                    clean_result[key] = value.to_dict('records')
                elif isinstance(value, (int, float, str, bool, list, dict)) or value is None:
                    clean_result[key] = value
                else:
                    clean_result[key] = str(value)

            # NO aplicar compensaciones - usar resultados puros
            clean_result['adjusted_total_pnl'] = strategy_result.get('total_pnl', 0)
            clean_result['compensation_applied'] = 0.0
            clean_result['compensation_success_rate'] = 0.0
            clean_result['compensated_trades'] = 0

            dashboard_data['strategies'][strategy_name] = clean_result

            # Actualizar resumen
            pnl = strategy_result.get('total_pnl', 0)
            if pnl > dashboard_data['summary']['best_pnl']:
                dashboard_data['summary']['best_pnl'] = pnl
                dashboard_data['summary']['best_strategy'] = strategy_name

            dashboard_data['summary']['total_trades'] += strategy_result.get('total_trades', 0)

            win_rate = strategy_result.get('win_rate', 0)
            if win_rate > 0:
                win_rates.append(win_rate)

            # Agregar m√©tricas de compensaci√≥n
            dashboard_data['summary']['total_compensated_trades'] += strategy_result.get('compensated_trades', 0)
            dashboard_data['summary']['total_compensation_pnl'] += strategy_result.get('total_compensation_pnl', 0.0)

            comp_rate = strategy_result.get('compensation_success_rate', 0)
            if comp_rate > 0:
                compensation_rates.append(comp_rate)

        # Calcular promedios
        if win_rates:
            dashboard_data['summary']['avg_win_rate'] = sum(win_rates) / len(win_rates)

        if compensation_rates:
            dashboard_data['summary']['avg_compensation_rate'] = sum(compensation_rates) / len(compensation_rates)

        # Guardar archivo JSON
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(dashboard_data, f, indent=2, ensure_ascii=False)

        logger.info(f"‚úÖ Resultados guardados para dashboard: {results_file}")

    except Exception as e:
        logger.error(f"‚ùå Error guardando resultados para dashboard: {e}")

async def save_global_summary(all_results: dict, config, logger):
    """
    Guarda un resumen global de todos los s√≠mbolos para el dashboard
    """
    try:
        results_dir = Path("data/dashboard_results")
        summary_file = results_dir / "global_summary.json"

        global_summary = {
            'timestamp': datetime.now().isoformat(),
            'total_symbols': len(all_results),
            'symbols': list(all_results.keys()),
            'config': {
                'timeframe': config.backtesting.timeframe,
                'start_date': config.backtesting.start_date,
                'end_date': config.backtesting.end_date,
                'initial_capital': config.backtesting.initial_capital
            },
            'metrics': {
                'total_pnl': 0.0,
                'total_trades': 0,
                'profitable_symbols': 0,
                'avg_win_rate': 0.0,
                'total_compensated_trades': 0,
                'total_compensation_pnl': 0.0,
                'avg_compensation_rate': 0.0
            }
        }

        win_rates = []
        compensation_rates = []

        for symbol, strategies in all_results.items():
            best_strategy = max(strategies.items(), key=lambda x: x[1].get('total_pnl', -10000))
            strategy_name, result = best_strategy

            pnl = result.get('total_pnl', 0)
            global_summary['metrics']['total_pnl'] += pnl
            global_summary['metrics']['total_trades'] += result.get('total_trades', 0)

            if pnl > 0:
                global_summary['metrics']['profitable_symbols'] += 1

            win_rate = result.get('win_rate', 0)
            if win_rate > 0:
                win_rates.append(win_rate)

            # M√©tricas de compensaci√≥n
            global_summary['metrics']['total_compensated_trades'] += result.get('compensated_trades', 0)
            global_summary['metrics']['total_compensation_pnl'] += result.get('total_compensation_pnl', 0.0)

            comp_rate = result.get('compensation_success_rate', 0)
            if comp_rate > 0:
                compensation_rates.append(comp_rate)

        # Calcular promedios
        if win_rates:
            global_summary['metrics']['avg_win_rate'] = sum(win_rates) / len(win_rates)

        if compensation_rates:
            global_summary['metrics']['avg_compensation_rate'] = sum(compensation_rates) / len(compensation_rates)

        # Guardar resumen global
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(global_summary, f, indent=2, ensure_ascii=False)

        logger.info(f"‚úÖ Resumen global guardado: {summary_file}")

    except Exception as e:
        logger.error(f"‚ùå Error guardando resumen global: {e}")

if __name__ == "__main__":
    print("[INFO] Iniciando Bot Trader Copilot...")
    asyncio.run(main())
    print("[SUCCESS] Programa finalizado.")
